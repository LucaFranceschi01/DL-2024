{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student 1: Alejandro González Álvarez\n",
    "\n",
    "NIA 1: 252658\n",
    "\n",
    "Student 2: Luca Franceschi\n",
    "\n",
    "NIA 2: 253885\n",
    "\n",
    "Student 3: Júlia Othats-Dalès\n",
    "\n",
    "NIA 3: 254435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideas\n",
    "\n",
    "'''\n",
    "classification of doppelgangers: to which person are you more alike?\n",
    "\n",
    "input: one facial image\n",
    "output: closest face in the feature space\n",
    "\n",
    "pretrained model for image recognition?\n",
    "triplet loss?\n",
    "siamese network?\n",
    "\n",
    "use transfer learning or train with vggface2?\n",
    "fine tune with smaller dataset of doppelgangers\n",
    "\n",
    "contrastive learning\n",
    "https://encord.com/blog/guide-to-contrastive-learning/\n",
    "https://www.v7labs.com/blog/contrastive-learning-guide\n",
    "https://arxiv.org/pdf/1512.03385\n",
    "https://www.geeksforgeeks.org/residual-networks-resnet-deep-learning/\n",
    "https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py\n",
    "https://www.v7labs.com/blog/triplet-loss\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html\n",
    "https://medium.com/@Skpd/triplet-loss-on-imagenet-dataset-a2b29b8c2952\n",
    "https://omoindrot.github.io/triplet-loss\n",
    "https://arxiv.org/pdf/1503.03832v3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment if not in Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_path = '/content/drive/My Drive/DeepLearning_2024/P4/Data/'\n",
    "# results_path = '/content/drive/My Drive/DeepLearning_2024/P4/Results/'\n",
    "\n",
    "# Comment if in Google Colab\n",
    "data_path = 'data/'\n",
    "results_path = 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print if gpu acceleration is enabled\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The HDA Doppelgaenger Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDA_Doppelgaenger(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, datadir = data_path, dataset_version = 'dataset.json', seed = None):\n",
    "\n",
    "        self.datadir = datadir\n",
    "        if seed != None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        with open('./' + dataset_version, 'r') as fp:\n",
    "            self.indexer = json.load(fp)['HDA_Doppelgaenger']\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        neg_idx = np.random.randint(0, len(self.indexer)) # index\n",
    "        neg_type = np.random.choice([0, 1]) # original or lookalike\n",
    "\n",
    "        anchor = Image.open(self.datadir + self.indexer[index][0])\n",
    "        positive = Image.open(self.datadir + self.indexer[index][1])\n",
    "        negative = Image.open(self.datadir + self.indexer[neg_idx][neg_type])\n",
    "\n",
    "        # if self.transform is not None :\n",
    "        #     anchor = self.transform(anchor)\n",
    "        #     positive = self.transform(positive)\n",
    "        #     negative = self.transform(negative)\n",
    "\n",
    "        return anchor, positive, negative\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indexer)\n",
    "    \n",
    "    def mean(self):\n",
    "        sum = np.zeros(3)\n",
    "        for i in range(len(self)):\n",
    "            sum += np.array(self[i][0]).sum(axis=(0,1))\n",
    "            sum += np.array(self[i][1]).sum(axis=(0,1))\n",
    "        return sum / (len(self)*2) / 255 / 256**2\n",
    "    \n",
    "    def mean_std(self):\n",
    "        mean = self.mean()\n",
    "\n",
    "        sum = np.zeros(3)\n",
    "        for i in range(len(self)):\n",
    "            sum += np.power(np.array(self[i][0]), 2).sum(axis=(0,1))\n",
    "            sum += np.power(np.array(self[i][1]), 2).sum(axis=(0,1))\n",
    "        sum = sum / (len(self)*2) / 255 / 256**2\n",
    "        \n",
    "        return mean, np.sqrt(sum - np.power(mean, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDA_Subset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        a, p, n = self.subset[index]\n",
    "        if self.transform:\n",
    "            a = self.transform(a)\n",
    "            p = self.transform(p)\n",
    "            n = self.transform(n)\n",
    "        return a, p, n\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HDA_Doppelgaenger(dataset_version='F_dataset.json')\n",
    "\n",
    "HDA_mean, HDA_std = dataset.mean_std()\n",
    "\n",
    "base_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(HDA_mean, HDA_std)])\n",
    "\n",
    "augm_transform = transforms.Compose(\n",
    "     [transforms.RandomHorizontalFlip(0.5),\n",
    "     transforms.RandomGrayscale(0.2),\n",
    "     transforms.ColorJitter(0.5, 0.5, 0.5, 0.5),\n",
    "     transforms.RandomAffine(45),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(HDA_mean, HDA_std)])\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, sharex=True, sharey=True)\n",
    "\n",
    "axs[0].imshow(dataset[0][0])\n",
    "axs[1].imshow(dataset[0][1])\n",
    "axs[2].imshow(dataset[0][2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean and Standard Deviation of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 10 # the batches' size will be = len(dataset) / reduction\n",
    "\n",
    "generator = torch.Generator().manual_seed(fixed_seed) # to have reproducible results\n",
    "train, validation, test = random_split(dataset, [0.85, 0.1, 0.05], generator=generator)\n",
    "\n",
    "train = HDA_Subset(train, augm_transform)\n",
    "validation = HDA_Subset(validation, base_transform)\n",
    "test = HDA_Subset(test, base_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=int(len(train)/reduction), shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation, batch_size=int(len(validation)/reduction), shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=int(len(test)/reduction), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toimage = transforms.ToPILImage()\n",
    "toimage(validation[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our re-implementation of the ResNet-18 architecture extracted from [the torchvision github repository](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py). We believe that it is important to note that it is not a simple copy-paste, we have put our best efforts in understanding and re-implementing it to fufill our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic ResNet building block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, norm_layer=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1, bias=False) # in this one stride = 1 then image shape is kept\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x): # Tip for improving performance merge all into one line relu(bn2(conv2(relu(bn1(conv1(x))))))\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, layers, num_classes=1000, zero_init_residual=False, norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        # Introduction layer\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Layers\n",
    "        self.layer1 = self._make_layer(64, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(64, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Last fully connected layer\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        # What is going on ???\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        # if zero_init_residual:\n",
    "        #     for m in self.modules():\n",
    "        #         if isinstance(m, Bottleneck):\n",
    "        #             nn.init.constant_(m.bn3.weight, 0)\n",
    "        #         elif isinstance(m, BasicBlock):\n",
    "        #             nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, in_planes, out_planes, blocks, stride=1):\n",
    "        '''\n",
    "        Creates a layer containing {blocks} ResidualBlocks, where the first one downsamples the output if needed,\n",
    "        and the next {blocks-1} stacked blocks keep the amount of filters unaltered.\n",
    "        '''\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        if stride != 1 or in_planes != out_planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False),\n",
    "                norm_layer(out_planes)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_planes, out_planes, stride, downsample, norm_layer))\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResidualBlock(out_planes, out_planes, norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(ResNet([2, 2, 2, 2], 1000), input_size=(128,3,256,256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How pretrained weights are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_weights = ResNet18_Weights.DEFAULT.get_state_dict()\n",
    "# net = ResNet([2, 2, 2, 2]).to(device)\n",
    "# net.load_state_dict(pretrained_weights)\n",
    "# # TRY WITH fishernet vgg16\n",
    "# net.fc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet([2, 2, 2, 2]).to(device)\n",
    "pretrained_weights = torch.load(results_path + 'default.ckpt', weights_only=True, map_location=device)\n",
    "net.fc = None\n",
    "net.load_state_dict(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, net, validation_loss, model_name):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "\n",
    "            # save trained model\n",
    "            torch.save(net.state_dict(), results_path + model_name)\n",
    "\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, val_loader):\n",
    "    net.eval()\n",
    "\n",
    "    loss_list = []\n",
    "\n",
    "    criterion = nn.TripletMarginLoss()\n",
    "\n",
    "    val_loss_epoch = 0\n",
    "\n",
    "    for anchors, positives, negatives in val_loader: # batches of positive, negative and anchor images\n",
    "\n",
    "        anchors = anchors.to(device)\n",
    "        positives = positives.to(device)\n",
    "        negatives = negatives.to(device)\n",
    "\n",
    "        out_anc = net(anchors)\n",
    "        out_pos = net(positives)\n",
    "        out_neg = net(negatives)\n",
    "\n",
    "        loss = criterion(out_anc, out_pos, out_neg)\n",
    "\n",
    "        val_loss_epoch += loss.cpu().item()\n",
    "        \n",
    "        loss_list.append(loss.cpu().item())\n",
    "\n",
    "    return val_loss_epoch / len(val_loader), loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, tr_loader, val_loader, epochs=10, optimizer=None, model_name='default.ckpt'):\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    loss_list = {\n",
    "        'training': [],\n",
    "        'validation': []\n",
    "    }\n",
    "\n",
    "    criterion = nn.TripletMarginLoss()\n",
    "\n",
    "    early_stopper = EarlyStopper(patience=3, min_delta=0.1)\n",
    "\n",
    "    for e in range(0, epochs):\n",
    "\n",
    "        loss_list['training'].append([])\n",
    "        loss_list['validation'].append([])\n",
    "\n",
    "        tr_loss_epoch = 0\n",
    "\n",
    "        for anchors, positives, negatives in tr_loader: # batches of positive, negative and anchor images\n",
    "\n",
    "            anchors = anchors.to(device)\n",
    "            positives = positives.to(device)\n",
    "            negatives = negatives.to(device)\n",
    "\n",
    "            out_anc = net(anchors)\n",
    "            out_pos = net(positives)\n",
    "            out_neg = net(negatives)\n",
    "\n",
    "            loss = criterion(out_anc, out_pos, out_neg)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tr_loss_epoch += loss.cpu().item()\n",
    "            \n",
    "            loss_list['training'][e].append(loss.cpu().item())\n",
    "\n",
    "        tr_loss_epoch /= len(tr_loader)\n",
    "\n",
    "        val_loss_epoch, val_loss_list = validate(net, val_loader)\n",
    "        loss_list['validation'][e] = val_loss_list\n",
    "\n",
    "        print('Epoch [{:4n}/{:4n}] | Train Loss: {:.4f} | Validation Loss: {:4n}'.format(e+1, epochs, tr_loss_epoch, val_loss_epoch))\n",
    "\n",
    "        if early_stopper.early_stop(net, val_loss_epoch, model_name):\n",
    "            return loss_list\n",
    "        \n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, test_loader):\n",
    "\n",
    "    correct = wrong = 0\n",
    "    \n",
    "    for anchor, positive, negative in test_loader: # batches of positive, negative and anchor images\n",
    "\n",
    "        anchor = anchor.to(device)\n",
    "        positive = positive.to(device)\n",
    "        negative = negative.to(device)\n",
    "\n",
    "        out_anc = net(anchor).flatten().detach().cpu().numpy()\n",
    "        out_pos = net(positive).flatten().detach().cpu().numpy()\n",
    "        out_neg = net(negative).flatten().detach().cpu().numpy()\n",
    "\n",
    "        near = np.linalg.norm(out_anc - out_pos, 2)\n",
    "        far = np.linalg.norm(out_anc - out_neg, 2)\n",
    "\n",
    "        if far > near:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "\n",
    "        # TODO: PRINT IMAGES, LATENT SPACE, ETC --> BASICALLY TEST IS FOR VISUALIZATION OF SPECIFIC RESULTS\n",
    "\n",
    "        print('Doppelgaengers: {:.4f}, Non doppelgaengers: {:.4f}'.format(near, far))\n",
    "\n",
    "    print('Correct: {:4n}, Wrong: {:4n}'.format(correct, wrong))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate, weight_decay=1e-5)\n",
    "list_loss = fit(net, train_loader, validation_loader, 10, optimizer=optimizer)\n",
    "\n",
    "sio.savemat(results_path + 'list_loss.mat', list_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadedDict = {}\n",
    "# sio.loadmat('list_loss.mat', loadedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(list_loss['training'][0], linestyle='-.', color='r', label='Training')\n",
    "plt.plot(list_loss['validation'][0], linestyle='-', color='b', label='Validation')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(net, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
