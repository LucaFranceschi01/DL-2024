{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sIlERrIm4xx"
      },
      "source": [
        "# Practice 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyeB4Obm4x2"
      },
      "source": [
        "Student 1: Alejandro González Álvarez\n",
        "\n",
        "NIA 1: 252658\n",
        "\n",
        "Student 2: Luca Franceschi\n",
        "\n",
        "NIA 2: 253885\n",
        "\n",
        "Student 3: Júlia Othats-Dalès\n",
        "\n",
        "NIA 3: 254435"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxUeZ36Km4x2"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PZhFCRzMm4x3"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVVWDwOEm4x5"
      },
      "source": [
        "# Google Drive (or not)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbFAwiBvm4x5",
        "outputId": "0c541763-eed3-49ac-d08f-ac2f41c7cee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Comment if not in Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "datadir = '/content/drive/My Drive/DeepLearning_2024/P2/Data/'\n",
        "#datadir = 'Data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBU6-pwOm4x6"
      },
      "source": [
        "# GPU Acceleration (or not)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFKUv2J1m4x6",
        "outputId": "c5bd77eb-b784-4bad-9513-78ac4d227083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Print if gpu acceleration is enabled\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1WSF05s1023"
      },
      "source": [
        "# Ex.1 - Experimenting with Multi-Class Sequence Classification using RNNs and LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bAW1k6R1vgk"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Experimenting with Multi-Class Sequence Classification using RNNs and LSTMs\n",
        "Steps :\n",
        "1. Load and visualize the training and testing data in 'data/P2_E1.csv' as shown in the following code cell.\n",
        "2. Following section 2 in the examples, train a RNN or LSTM to solve the multi-class sequence classification problem:\n",
        "  -   Adapt the classification loss and the SequenceClassifier module\n",
        "  -   Adapt the test_sequence_classifier function to compute the multi-class accuracy and be able to visualize the confusion matrix\n",
        "3. Experiment with different models by changing different hyper-parameters (e.g, num_layers, hidden_size, optimiziers, activation_functions for RNNs, etc..) and evaluate  the results for each of them on the testing set.\n",
        "4. Visualize analyse and discuss the results in the report.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJoitFCf-9F1"
      },
      "source": [
        "# Sol 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEF-ZsLvYDMR"
      },
      "outputs": [],
      "source": [
        "# 1. Load and visualize the training and testing data\n",
        "data = np.load(datadir+'P2_E1.npz')\n",
        "X_train, X_test = data['X_train'], data['X_test']\n",
        "Y_train, Y_test = data['Y_train'], data['Y_test']\n",
        "\n",
        "print(f'Train Seqs: {X_train.shape}')\n",
        "print(f'Train Labels: {Y_train.shape}')\n",
        "print(f'Test Seqs: {X_test.shape}')\n",
        "print(f'Test Labels: {Y_test.shape}')\n",
        "\n",
        "classes = np.unique(Y_train)\n",
        "n_classes = len(classes)\n",
        "colors = plt.cm.rainbow(np.linspace(0, 1, n_classes))\n",
        "\n",
        "fig, axs = plt.subplots(n_classes, 1, figsize=(10, 5*n_classes))\n",
        "for class_idx in range(0, n_classes):\n",
        "  axs[class_idx].plot(X_test[Y_test == class_idx, :].T,'-o',\n",
        "                      c=colors[class_idx])\n",
        "  axs[class_idx].set_title(f'Tests Seqs. - Class {class_idx}')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "81-kCVEsm4x8"
      },
      "outputs": [],
      "source": [
        "# Define module encapsulating a Sequence Classifier using RNN or LSTMs and setting different architecture hyper-parameters\n",
        "\n",
        "class SequenceClassifier(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_size : int = 1,\n",
        "               hidden_size : int = 5,\n",
        "               num_layers = 1,\n",
        "               num_classes : int = 6,\n",
        "               use_lstm : bool = False):\n",
        "    # Define RNN or LSTM architecture\n",
        "    super().__init__()\n",
        "    self.use_lstm = use_lstm\n",
        "    if(use_lstm):\n",
        "      self.rnn =  nn.LSTM(input_size = input_size, hidden_size = hidden_size,\n",
        "                          num_layers=num_layers, batch_first = True)\n",
        "    else:\n",
        "      self.rnn =  nn.RNN(input_size = input_size, hidden_size = hidden_size,\n",
        "                         num_layers=num_layers, batch_first = True)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.last_linear = nn.Linear(hidden_size, num_classes)  # 6 is number of different classes\n",
        "\n",
        "  def forward(self, X):\n",
        "    _, last_states = self.rnn(X)\n",
        "    # Get last hidden state for last layer. Ignore cell state in case of LSTMs\n",
        "    if(not self.use_lstm):\n",
        "      last_hidden_state = last_states[-1,:,:].squeeze(0)\n",
        "    else:\n",
        "      last_hidden_state = last_states[0][-1,:,:].squeeze(0)\n",
        "    # Get sequence label probability using the last hidden state\n",
        "    output = self.softmax(self.last_linear(last_hidden_state))  # Using softmax instead of sigmoid\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training model\n",
        "def train_multiclass_classifier(X_train, Y_train, classifier, optimizer, loss_func, epochs=100):\n",
        "  loss_epochs = []\n",
        "  for epoch in range(epochs):\n",
        "      optimizer.zero_grad()\n",
        "      output = classifier(X_train)\n",
        "      loss = loss_func(output, Y_train)\n",
        "      loss_epochs.append(loss.item())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "  print(f'Final loss: {loss.item()}')\n",
        "  return np.asarray(loss_epochs)\n",
        "\n",
        "# Adapt the test_sequence_classifier function\n",
        "def test_multiclass_classifier(X_test, Y_test, classifier, prob_threshold=0.5):\n",
        "  output = classifier(X_test)\n",
        "  predicted_labels = torch.argmax(output, dim=1)\n",
        "  correct_predictions = (predicted_labels == Y_test).sum().item()\n",
        "  total_samples = len(Y_test)\n",
        "  accuracy = correct_predictions / total_samples\n",
        "  print(f'Test Accuracy: {accuracy:.4f}')\n",
        "  return accuracy\n"
      ],
      "metadata": {
        "id": "WmqAWB7VwGDE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pt = torch.from_numpy(X_train).float().unsqueeze(2).cuda()\n",
        "Y_train_pt = torch.from_numpy(Y_train).long().cuda()\n",
        "X_test_pt = torch.from_numpy(X_test).float().unsqueeze(2).cuda()\n",
        "Y_test_pt = torch.from_numpy(Y_test).long().cuda()\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "exp_hidden_size = [1, 5]\n",
        "exp_num_layers = [1, 2]\n",
        "exp_use_lstm = [False, True]\n",
        "\n",
        "losses_models = {}\n",
        "test_accuracy_models = {}\n",
        "\n",
        "for hidden_size, num_layers, use_lstm in zip(exp_hidden_size,exp_num_layers,exp_use_lstm):\n",
        "\n",
        "  model_id = f'H{hidden_size}_NL{num_layers}_LSTM{int(use_lstm)}'\n",
        "  print(f'Training: {model_id}')\n",
        "\n",
        "  seq_classifier = SequenceClassifier(use_lstm=use_lstm, num_layers=num_layers, hidden_size=hidden_size)\n",
        "  seq_classifier.cuda()\n",
        "\n",
        "  optimizer = torch.optim.Adam(seq_classifier.parameters(), lr=1e-3)\n",
        "\n",
        "  losses_models[model_id] = train_multiclass_classifier(X_train_pt, Y_train_pt,\n",
        "                                                        seq_classifier, optimizer,\n",
        "                                                        loss_func, epochs=1000)\n",
        "\n",
        "  test_accuracy_models[model_id] = test_multiclass_classifier(X_test_pt, Y_test_pt, seq_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL_77ZCXx668",
        "outputId": "b32e09da-223e-425c-b014-829488af0ef9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: H1_NL1_LSTM0\n",
            "Final loss: 1.7791435718536377\n",
            "Test Accuracy: 0.2000\n",
            "Training: H5_NL2_LSTM1\n",
            "Final loss: 1.4122083187103271\n",
            "Test Accuracy: 0.5889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for loss_it in losses_models.values():\n",
        "  plt.plot(loss_it)\n",
        "plt.legend(losses_models.keys())\n",
        "plt.show()\n",
        "\n",
        "pd.DataFrame(np.asarray(list(test_accuracy_models.values()))*100, columns=['accuracy %'],\n",
        "             index=test_accuracy_models.keys()).transpose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "2oR0V1t60CBv",
        "outputId": "b6e7327c-31b3-4789-d5e7-0968b433acdc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABYtUlEQVR4nO3dd3gVZd7G8e8pqYQktDQIvUoXJDQLCiIqil1Epekuii6KFX1FXF1x7agIFpprQVHBhqwIiwgCGiAqokgJ0pJQUyH1zPvHJCc5JIEkJJmT5P5c11xnzswzc34zq+bemWeesRmGYSAiIiLixexWFyAiIiJyOgosIiIi4vUUWERERMTrKbCIiIiI11NgEREREa+nwCIiIiJeT4FFREREvJ4Ci4iIiHg9p9UFVBaXy8WBAweoX78+NpvN6nJERESkDAzDIC0tjaioKOz20q+j1JrAcuDAAaKjo60uQ0RERCpg7969NGvWrNT1tSaw1K9fHzAPODg42OJqREREpCxSU1OJjo52/x0vTa0JLAW3gYKDgxVYREREapjTdedQp1sRERHxegosIiIi4vUUWERERMTrKbCIiIiI11NgEREREa+nwCIiIiJeT4FFREREvJ4Ci4iIiHg9BRYRERHxeuUOLKtXr2b48OFERUVhs9lYsmTJabd577336N69O4GBgURGRjJu3DiOHDni0WbRokV07NgRf39/unbtytKlS8tbmoiIiNRS5Q4sGRkZdO/enZkzZ5ap/dq1a7n11lsZP348v/32G4sWLeLHH3/k9ttvd7f54YcfGDlyJOPHj2fz5s2MGDGCESNGsGXLlvKWJyIiIrWQzTAMo8Ib22wsXryYESNGlNrm+eefZ9asWezcudO97NVXX+Xf//43+/btA+CGG24gIyODL7/80t2mb9++9OjRg9mzZ5epltTUVEJCQkhJSdG7hERERGqIsv79rvKXH/br149HHnmEpUuXMmzYMA4ePMjHH3/MpZde6m6zbt06Jk+e7LHd0KFDy3S7qao9/99tZOe5CAnwISTAh9BAH0IDfAkNNL+HBPpQ38952pc2iYiISMVVeWAZMGAA7733HjfccAOZmZnk5uYyfPhwj1tKiYmJhIeHe2wXHh5OYmJiqfvNysoiKyvL/T01NbXyiwcW/rSXw+lZp2zjsNvcgaYw1BQEGl9C85eFuD/NwFPf34mf01EldYuIiNQmVR5Ytm7dyqRJk5g6dSpDhw4lISGBBx54gAkTJjBnzpwK73f69Ok88cQTlVhpyW47txVH0rNIOZFD8vEckk/kkHI8x/x+IpvMHBd5LoOjGdkczcgu9/59nXaC/Z3U9zcDTH1/J/X9zPmg/OXBBcvdbfI//cx5fx+7rvCIiEitVuWBZfr06QwYMIAHHngAgG7dulGvXj3OPfdcnnrqKSIjI4mIiCApKclju6SkJCIiIkrd75QpUzxuI6WmphIdHV3p9U84v80p12fm5JFyIqcw0BzPJvlEDqnugJNNcn7AKdomLSsXw4DsXBeH07M5nF7+sFPAabe5A049Xyf1/JwE+jqo5+sk0M9BkJ+TQF8n9XwdBPoVfgb5OfKXm+3Mbc1lDrsCkIiIeI8qDyzHjx/H6fT8GYfDvA1S0N+3X79+rFixgnvuucfdZvny5fTr16/U/fr5+eHn51f5BZeTv48Dfx8H4cH+5douz2WQnpVLWmYOaZm5+VOO+zM1f1l6Vknrc0nNzCE9P/TkugyOHc/h2PGcSjsuP6edAF8HAT6Ows/8eX+f4t8D89v4e7S1F7YtYV9Oh4YBEhGRsil3YElPT2fHjh3u7/Hx8cTFxdGwYUOaN2/OlClT2L9/P++88w4Aw4cP5/bbb2fWrFnuW0L33HMPffr0ISoqCoBJkyZx/vnn88ILL3DZZZexcOFCYmNjefPNNyvpML1P0X4vFeVyGWRk57pDTHpWDsez88jIyuN4di4Z2Xkcz8olIyt/Pju3cF2RNhlF2uS5zBCZlesiK9dFMpUXgk7m47AVCzQnhx9/Z37wceYHJV8Hfs7CIGQGRjsBPg78iswXXe/ntGPXFSMRkRqt3I81r1q1ikGDBhVbPnr0aObPn8+YMWPYvXs3q1atcq979dVXmT17NvHx8YSGhnLhhRfy73//m6ZNm7rbLFq0iP/7v/9j9+7dtGvXjmeffdbjSaLT0WPNZ84wDLLzXBzPyiMjO5fMHBcnsvM4kZM/ZeeRWWTe4zMnj8yT2hb9zMyfP56TR8UfpK+4gpBTNND4+TgI8Mlf7iy4WmTHr2DeWXiVyN9ZEKDs7uBkhii7+ypbwb515UhEpOzK+vf7jMZh8SZVFli+ug9yMiGwIQQ2yp+KzAc0hIBQsOtpn7IoCEWZ2S6O5+SeFGhcHuHneHYuJ3JcZObkkZlrLsvMcZGZmx+ecvPXuSeXe1+ZOXnk5Fnzj7bTbivxio9nuCkSloquLxKc3Psossy/SJjy87Hj51SHaxGp2bxmHJYa77clcPzwaRrZIKDBSWGmoRlm3CEnf1lQOIREg6NunnqbzYaf04Gf00EIFb8dVhZ5LsN9Ragg0JQWboquP1FkfVZ+WDpxUljKynUV23eBXJdBWlYuaVm5VXp8ADYb7is9Ra8c+Trt+Dns+PnY8S3y6es0ryD5OgvmzU+zjQM/x0nLi7Yvur+T9qNO2iJS1ermX83yGPw4pB+E40fhxFE4fiR/OmpOWSmAYa47cRSOnHaPYHdCaHNo2Boat4eos6Hp2eZ3/b/lSuOw26jnZz41VdUMw3CHmKJhqOAzyyMguYosLwxIRcNSlvsqUmFYyipyZamgr5Fh4L4qdawK+xudjtNu8wg6Pg4z2DgdNnwcdpwOO74OG067uazoOnOy4XTY8bGf1L7oersNH6cdH7sdH6e5r4J1dru53mG34bDZcDpsOOx2nHYbdvd3c53Dnv+9YN5ux+Hx3aY+TyJeSLeEzlRuNpw4dlKYKRJoCr6fOAoZhyEtEfJKGYgusBG0HQztLzEn38DqOw6pUXLyXKWGocycPLLzO01n5xWZz/8smDe/m+uz81xk5ZifRZcX3c5sk2d+5ros6YtUndwByF4YZBx2Ow47Zsg5aV1JwchjshUGK3tBsLIXX3aq7RwFv+NuDw6H3WNfDjtmnbYi83byt7Njt+MOdR7LihzHyb9fMG8/qY3TbtMtSTlj6sPirVwuSDsAR3eZU9JWOLAJEn7xDDL+IdBjFPS53bzyIuJFDMMg12V4hJqCoFMQbnLzDHLzisy7XGTnL8vJc5GTZ5CTvy7H5SInt6BN/rL8Nu72LoOcXBe5roJ1he3yDIM8F+S5zPV5RaZcl4Er/9NzuQtXrfivn7VsNkoMOk675xU0n/zbjQXLC67E+TiKtytcbwaqgnn3uvwrdH4eHd/t+d9P6i/mtKsjvJdTYKlpcrNh30/w59ew9TNI3mMutzuh93i44GGzD4yIVBrDKAw1eS7DDD55+SEnP5Tl5RWEG/N7bl6RdScFozyXyx2c8lwUbpe/TeE6gzyjsF1BGzN4eS5zGcWDV8GyvKJ158977stzmcd2pSzLcxXfd03/K+HjsOV3VPcMOP5OB/X8nAT5mYNmBvn5EOSXv8w/f7lv4XyQn5PgAHP0cYWgyqPAUpO5XLBzBax/HXauNJcFhcOVM6HdEGtrE5E6x1UkzBSENZfr1OEnJz/o5eQVXhHLyXORnVuw3Lyqll3kall2kXYe2+Wa80WvvhXcmszKKewQX/S2aFau6/QHdgaC/Z2EBvrSINB8Z1yD/HfIhQaa74prFORHkyA/mtQ3p2B/vSS3NAostcWuVbD0QTi8zfx+/kNwwRR1zhUROQWXK38IhZM6tmcWCThZOeZAm+lZue4po2A+M5eMbPPTXF7YriJ8nXaaBPnRuL5nkAmr70dkiD8RIf5EhgTQINCnzgUbBZbaJOcELH8cfnzD/N5jFAx/pc4+Gi0iYpXcPBcpJ8xXoaScyOZYhvlS3OTj2e73xx3LyOFwehaH07M4lJZFambZQ46v024GmGD//CATUCTQmJ+N6/nVqifZNA5LbeITAJc+C2GdzIHs4t4DbHDla7rSIiJSjZwOO42C/GgUVPZ32WXm5LnDy6G0LA4VmU9KzSQxNZPElEwOp2eTneviryPH+evI8dJrsNsID/b3CDLhweYUVt+PsPzP6hjSoTrVrqOp7XqPhXqN4aPREPcu1GsEQ/5pdVUiInIK/j4OmjUIpFmDUw9VkZWbx8HULBJSMklIOUFiSiYJKWaYSUjNJDHlBAfTssh1GexPPsH+5BOn3F89Xwdhwf7uW09h9f0JC/ajcZAfoQE+NKjnk98Px5eQAB+vHwBSt4Rqos3vwmcTzflr5kDXa62tR0REqkVOnotDaVmFQaYg2KRmcig1i4NpmRxMy+J4dl659x3s76RBPd/CzsQBPtT3dxLkZ34G+zsZ0bMp9f0rd5Ry3RKqzXreDEfj4fvn4YtJENkdGrezuioREaliPg47UaEBRIUGnLJdelYuB1PN8HIw//bTwTQz1BzOyHb3uTl2PJu0/D42qZm5pGbmnvJ21MWdIyo9sJSVAktNdcEU2LMe/loDH4+F2/8HDmv+IRIREe8S5OckqEkQrZsEnbZtTn5H4sIQYwaZ1BM5pGbmkpaZQ1r+Z7BFYQUUWGouhxOueRtm9YPEX80xWwZMsroqERGpYXwcdhoHmX1bvJmG6qvJgiPh4qfM+f9Nh2O7LS1HRESkqiiw1HQ9RkHLcyH3BHz9sNXViIiIVAkFlprOZoPLXgSbw3wP0e41VlckIiJS6RRYaoMm7aHXGHP+m8fMdxGJiIjUIgostcUFD4NvEBzYBFuXWF2NiIhIpVJgqS2CwqD/P8z57/6tqywiIlKrKLDUJn0ngF8IHPoDfv/M6mpEREQqjQJLbeIfAn3vMOe/e05XWUREpNZQYKlt+k4Av2A4+Bts+8rqakRERCqFAkttE9AAYv5uzq9+DmrHuy1FRKSOU2CpjWLuAGcAJPyscVlERKRWUGCpjeo1gh43mfM/vGptLSIiIpVAgaW26jcRsMH2/8KhbVZXIyIickYUWGqrRm2g42Xm/LrXrK1FRETkDCmw1Gb97zY/f14I6QetrUVEROQMKLDUZtEx0OwcyMuGH9+yuhoREZEKU2CpzWy2wqssP70F2RnW1iMiIlJBCiy1XcfLoUErOHEMNv3H6mpEREQqRIGltrM7Cq+yrHsN8nKsrUdERKQCyh1YVq9ezfDhw4mKisJms7FkyZJTth8zZgw2m63Y1LlzZ3ebadOmFVvfsWPHch+MlKLHTVCvCaTshd8WW12NiIhIuZU7sGRkZNC9e3dmzpxZpvYzZswgISHBPe3du5eGDRty3XXXebTr3LmzR7s1azRCa6XxCSgcrn/tDA3XLyIiNY6zvBsMGzaMYcOGlbl9SEgIISEh7u9Llizh2LFjjB071rMQp5OIiIjyliNldc5tsOZlSNoCO76FdkOsrkhERKTMqr0Py5w5cxg8eDAtWrTwWL59+3aioqJo3bo1o0aNYs+ePafcT1ZWFqmpqR6TnEJAA+g1xpz//gVLSxERESmvag0sBw4c4Ouvv+a2227zWB4TE8P8+fNZtmwZs2bNIj4+nnPPPZe0tLRS9zV9+nT31ZuQkBCio6Oruvyar99EcPjCnnWwe63V1YiIiJRZtQaWBQsWEBoayogRIzyWDxs2jOuuu45u3boxdOhQli5dSnJyMh999FGp+5oyZQopKSnuae/evVVcfS0QHAU9bzbnv3/e2lpERETKodoCi2EYzJ07l1tuuQVfX99Ttg0NDaV9+/bs2LGj1DZ+fn4EBwd7TFIGA+4BmwN2roR9G62uRkREpEyqLbB899137Nixg/Hjx5+2bXp6Ojt37iQyMrIaKqtjGrSAbjeY87rKIiIiNUS5A0t6ejpxcXHExcUBEB8fT1xcnLuT7JQpU7j11luLbTdnzhxiYmLo0qVLsXX3338/3333Hbt37+aHH37gqquuwuFwMHLkyPKWJ2Vx7mTABtuWQuKvVlcjIiJyWuUOLLGxsfTs2ZOePXsCMHnyZHr27MnUqVMBSEhIKPaET0pKCp988kmpV1f27dvHyJEj6dChA9dffz2NGjVi/fr1NGnSpLzlSVk0bgedrzLn9cSQiIjUADbDqB2jiKWmphISEkJKSor6s5RF4haYPQCwwcQfoUl7qysSEZE6qKx/v/Uuoboqogt0uAwwYM2LVlcjIiJySgosddl595mfv3wER+OtrUVEROQUFFjqsqa9oM1FYOTB2petrkZERKRUCix13XkPmJ+b34OU/dbWIiIiUgoFlrquRT9oMRBcOfDDq1ZXIyIiUiIFFoHz7jc/N86H9IOWliIiIlISBRaB1hdA096QewJ+fNPqakRERIpRYBGw2aD/3eZ87DzIybS2HhERkZMosIip4+UQEg3HD8OWj62uRkRExIMCi5gcTuhzuzm/fhbUjgGQRUSkllBgkUJn3wo+gZC0BXavsboaERERNwUWKRTQALrnvyF7w2xraxERESlCgUU8xUwwP//4Co79ZW0tIiIi+RRYxFOT9tB6EGCY47KIiIh4AQUWKa73OPNz838gN9vaWkRERFBgkZJ0GAb1IyHjEPzxpdXViIiIKLBICRw+5hNDALFzra1FREQEBRYpzdmjwWaH3d/DoT+trkZEROo4BRYpWUhTaD/MnNdVFhERsZgCi5TunPzOtz+/D9nHra1FRETqNAUWKV3rC6FBS8hMgd8+tboaERGpwxRYpHR2O/Qaa87rtpCIiFhIgUVOrefN4PCF/RvhQJzV1YiISB2lwCKnVq8xnHWlOa+rLCIiYhEFFjm9gpFvf10EJ5ItLUVEROomBRY5veb9IOwsyDkOce9ZXY2IiNRBCixyejYbxPzdnN/wBrjyrK1HRETqHAUWKZuu10NAA0j+C7Z9bXU1IiJSxyiwSNn4BhY+4vz982AY1tYjIiJ1igKLlF3fO8EZAAc2w84VVlcjIiJ1iAKLlF1Qk8Inhr59AvJyrK1HRETqDAUWKZ8Bk8A/FBJ/MR9zFhERqQblDiyrV69m+PDhREVFYbPZWLJkySnbjxkzBpvNVmzq3LmzR7uZM2fSsmVL/P39iYmJ4ccffyxvaVId6ofDwHvM+R9eVV8WERGpFuUOLBkZGXTv3p2ZM2eWqf2MGTNISEhwT3v37qVhw4Zcd9117jYffvghkydP5vHHH2fTpk10796doUOHcvDgwfKWJ9Wh11jwDYKDW2HbUqurERGROsBmGBX/v8g2m43FixczYsSIMm+zZMkSrr76auLj42nRogUAMTExnHPOObz22msAuFwuoqOjufvuu3n44YfLtN/U1FRCQkJISUkhODi43Mci5fTtE7DmRQjvAn//3nxRooiISDmV9e93tf+VmTNnDoMHD3aHlezsbDZu3MjgwYMLi7LbGTx4MOvWrSt1P1lZWaSmpnpMUo363w1+wZC0BbYusboaERGp5ao1sBw4cICvv/6a2267zb3s8OHD5OXlER4e7tE2PDycxMTEUvc1ffp0QkJC3FN0dHSV1S0lCGwI/Saa899Og5xMS8sREZHarVoDy4IFCwgNDS3XLaTSTJkyhZSUFPe0d+/eMy9Qyqf/3VA/yhz9dv3rVlcjIiK1WLUFFsMwmDt3Lrfccgu+vr7u5Y0bN8bhcJCUlOTRPikpiYiIiFL35+fnR3BwsMck1cy3HgyeZs5//wKklX5FTERE5ExUW2D57rvv2LFjB+PHj/dY7uvrS69evVixonDkVJfLxYoVK+jXr191lScV1fU6aNobstNh5ZNWVyMiIrVUuQNLeno6cXFxxMXFARAfH09cXBx79uwBzFs1t956a7Ht5syZQ0xMDF26dCm2bvLkybz11lssWLCA33//nTvuuIOMjAzGjh1b3vKkutntcMkz5vzm9+BAnKXliIhI7eQs7waxsbEMGjTI/X3y5MkAjB49mvnz55OQkOAOLwVSUlL45JNPmDFjRon7vOGGGzh06BBTp04lMTGRHj16sGzZsmIdccVLRZ9jvs35149g2cMw9muw2ayuSkREapEzGofFm2gcFoul7IfXekPOcRgxG3qMtLoiERGpAbx2HBappUKawvkPmvPfPArHj1pbj4iI1CoKLFJ5+t0FYWfB8SPwclc49KfVFYmISC2hwCKVx+EDl79szmenw4c36+WIIiJSKRRYpHI1j4Fhz5rzh7fB53dZW4+IiNQKCixS+WL+Dm0uMuc3vwu/fmxtPSIiUuMpsEjVGLkQmvUx5z+5DZK2WluPiIjUaAosUjWcvjDqI2jQCjBg+WPgyrO6KhERqaEUWKTqBDSAG98Hmx12fGu+1VmdcEVEpAIUWKRqhZ8FV7xqzv/wCiybotAiIiLlpsAiVa/nzXDxv8z5DbNg0zvW1iMiIjWOAotUj/53weAnzPkv/mG+KFFERKSMFFik+vS7C1oMNOc/uxNi51lbj4iI1BgKLFJ9HE4Y/Tn0/4f5fekDZmdcERGR01Bgkepld8CQf0Kn4eDKgXevhY3zra5KRES8nAKLVD+bDa58HdpfAhjwxSR4MgwSt1hdmYiIeCkFFrGGf7A5Gm7MBPN7XhbMHgDTQmD189bWJiIiXkeBRaxjs8Elz8Cw5zyXr3wSjh+1piYREfFKCixiLZsNYv4G/3cQeo8vXP5sK3jrQkhLtK42ERHxGgos4h2cfnD5i3DLEnD4mcv2b4QXOsDGBZaWJiIi1lNgEe/SZhDcuwVGfQxOf3PZF5Pgx7esrUtERCylwCLeJygM2g2BO9dDu6GAAUvvhy8nq2+LiEgdpcAi3qthK/NJooGTze+xc2DuUEj42dq6RESk2imwiHez2+GiqXDDe1A/Cg7/CW+cZ15tUYdcEZE6Q4FFvJ/NBp0uh/HfQLM+5rLYOTCjO/w0x9raRESkWiiwSM0RGg23LTefJGrWB3Iz4avJ8MFISN5jdXUiIlKFFFik5mkzyLzacsEjYHfCtqUwMwbWvAS52VZXJyIiVUCBRWommw0ueAgmrIEWAyDnOHw7DWaeA3HvQ16u1RWKiEglUmCRmi2sE4z5CkbMgnpN4NhuWHIHvN4Xfv0YXC6rKxQRkUqgwCI1n80GPW6CST/D4CcgoCEc2Q6fjIfXY2Dzu7pVJCJSw9kMwzCsLqIypKamEhISQkpKCsHBwVaXI1bKTIUNb8C6VyEzxVxWP8p8Z1GvMRDQwNLyRESkUFn/fiuwSO2VmQob58O6mZCeP2aLT6B5NSbmDmjc1tLyREREgcXqcsSb5GaZ/VnWvw5JW/IX2qD9UOh7J7Q6z7ytJCIi1a6sf7/L3Ydl9erVDB8+nKioKGw2G0uWLDntNllZWTz66KO0aNECPz8/WrZsydy5c93r58+fj81m85j8/f3LW5pIyZx+0HOU+UTRrZ9D+0sAA/5cBu9cAbMHmv1ccjKtrlRERErhLO8GGRkZdO/enXHjxnH11VeXaZvrr7+epKQk5syZQ9u2bUlISMB10tMbwcHBbNu2zf3dpv/HK5XNZoPW55vT4R2wYTbEvWdedflsovlYdO/xcM548wWMIiLiNcodWIYNG8awYcPK3H7ZsmV899137Nq1i4YNGwLQsmXLYu1sNhsRERHlLUekYhq3hcuehwsfhY0L4Mc3IXU/fPcMfP88dLoC+t8FTXtZXamIiFANjzV//vnn9O7dm2effZamTZvSvn177r//fk6cOOHRLj09nRYtWhAdHc2VV17Jb7/9dsr9ZmVlkZqa6jGJlFtAAxh4j/lI9LVzodk54MqF3z6Fty6EOUPh5w91u0hExGJVHlh27drFmjVr2LJlC4sXL+bll1/m448/5s4773S36dChA3PnzuWzzz7j3XffxeVy0b9/f/bt21fqfqdPn05ISIh7io6OrupDkdrM4QNdroHbvjX7unS70Rz2f+96WPw3eLEjLHsEDv1pdaUiInXSGT0lZLPZWLx4MSNGjCi1zcUXX8z3339PYmIiISEhAHz66adce+21ZGRkEBAQUGybnJwcOnXqxMiRI3nyySdL3G9WVhZZWVnu76mpqURHR+spIak8qQlmZ9xNCyBlb+HyFgOh91joNNzs0CsiIhVW1qeEyt2HpbwiIyNp2rSpO6wAdOrUCcMw2LdvH+3atSu2jY+PDz179mTHjh2l7tfPzw8/P/2xkCoUHAnnPwDnToYdK2DjPPPJor/WmFNgI+gxyhyMrlEbq6sVEanVqvyW0IABAzhw4ADp6enuZX/++Sd2u51mzZqVuE1eXh6//vorkZGRVV2eyOnZHdD+Yhj5AdzzK5z/sDly7vEj8MMr8OrZsOAK+G0J5OVYXa2ISK1U7sCSnp5OXFwccXFxAMTHxxMXF8eePXsAmDJlCrfeequ7/U033USjRo0YO3YsW7duZfXq1TzwwAOMGzfOfTvon//8J9988w27du1i06ZN3Hzzzfz111/cdtttlXCIIpUopBkMmmIGlxs/gHYXAzaI/w4WjYaXu8Hq5yD9kNWViojUKuUOLLGxsfTs2ZOePXsCMHnyZHr27MnUqVMBSEhIcIcXgKCgIJYvX05ycjK9e/dm1KhRDB8+nFdeecXd5tixY9x+++106tSJSy+9lNTUVH744QfOOuusMz0+karhcELHS2HUIrjnFzjvAagXBmkHYOVT8NJZsHgCHNhsdaUiIrWChuYXqSy5WbD1M3NAuv0bC5c36wMxfzfHdnH6WlefiIgX0ruERKy0byP8+AZs+RRc+f1agiKg9zizk279cEvLExHxFgosIt4gLcl8Y3Ts3MI3Rjt8ofuN0H+S3hgtInWeAouIN8nNht8/N28X7fspf6ENOl0OA+6FZnoFgIjUTQosIt5qz3pY8zL8+XXhspbnwoBJ0Haw+ZJGEZE6QoFFxNsd/B3WvgK/fmS+vwjMly1e+H/QepCCi4jUCQosIjVFyj5Y97o5km7OcXNZiwFw4WPQop+1tYmIVLGy/v2u8pFuReQ0QprBJU+bb4zueyc4/OCvtTDvEnjvOjhc+isqRETqCgUWEW8RFAaXTId/bIJeY823RW//Bl7vC99Og+wMqysUEbGMAouItwlpBsNfhok/Qtsh5jgua16C186BnSutrk5ExBIKLCLeqlEbc+j/Gz+A0BaQuh/+cxV8db+utohInaPAIuLNbDbznUV3roM+fzOX/fQWvHkBHPrT0tJERKqTAotITeBbDy59Dm5ZAvWj4PCf8NaF8MdSqysTEakWCiwiNUmbQfD376B5f8hOg4U3wab/WF2ViEiVU2ARqWmCwmD053D2aMCAz+8y31VUO4ZUEhEpkQKLSE3k8IHhM6DP383vX94Lb54Px3ZbWpaISFVRYBGpqWw2uOQZ8x1EzgBI+BlmnwtbPrW6MhGRSqfAIlKT2e0w5J8wcT2EdYasVFg8ARJ/tboyEZFKpcAiUhs0aAl/X20ONJeXBR+NhsxUq6sSEak0CiwitYXDCVe/CcHN4OhO80pLzgmrqxIRqRQKLCK1SWBDuG6e+R6ibV/BnCFwNN7qqkREzpgCi0htE90Hbv4EAhubfVnePB/2bbS6KhGRM6LAIlIbtb7A7NPStDdkpsDHYyAr3eqqREQqTIFFpLYKaQq3LoHQ5pC8Bz69HfJyrK5KRKRCFFhEajO/+jD8FXN+21L46j5r6xERqSAFFpHars0guOTf5vymBfDLImvrERGpAAUWkbqg7wQ47wFz/vO7YccKa+sRESknBRaRuuK8B6HdUMg9AR+PNfu1iIjUEAosInWF0xdueLfwyaFFYyA3y+qqRETKRIFFpC5x+sK1cyGgAezfCEvvt7oiEZEyUWARqWsatIBr5oDNDpvegdh5VlckInJaCiwidVHbi+DCx8z5rx+CxC3W1iMichoKLCJ11cB7zU64eVnwyXi9KFFEvJoCi0hdZbPBiNchKBwO/QHf/J/VFYmIlKrcgWX16tUMHz6cqKgobDYbS5YsOe02WVlZPProo7Ro0QI/Pz9atmzJ3LlzPdosWrSIjh074u/vT9euXVm6dGl5SxOR8qrXGEbMMud/ehv+0L93IuKdyh1YMjIy6N69OzNnzizzNtdffz0rVqxgzpw5bNu2jQ8++IAOHTq41//www+MHDmS8ePHs3nzZkaMGMGIESPYskX31UWqXNuLoN9d5vxnEyE1wdp6RERKYDMMw6jwxjYbixcvZsSIEaW2WbZsGTfeeCO7du2iYcOGJba54YYbyMjI4Msvv3Qv69u3Lz169GD27NllqiU1NZWQkBBSUlIIDg4u13GI1Hm5WfD2YEj8BTpfBdfNt7oiEakjyvr3u8r7sHz++ef07t2bZ599lqZNm9K+fXvuv/9+Tpwo7OC3bt06Bg8e7LHd0KFDWbduXan7zcrKIjU11WMSkQpy+pn9WWx2+G0xxH9vdUUiIh6qPLDs2rWLNWvWsGXLFhYvXszLL7/Mxx9/zJ133uluk5iYSHh4uMd24eHhJCYmlrrf6dOnExIS4p6io6Or7BhE6oSIrtBrrDm/7GHIy7W2HhGRIqo8sLhcLmw2G++99x59+vTh0ksv5cUXX2TBggUeV1nKa8qUKaSkpLinvXv3VmLVInXUhf8H/qGQtAXi3rW6GhERtyoPLJGRkTRt2pSQkBD3sk6dOmEYBvv27QMgIiKCpKQkj+2SkpKIiIgodb9+fn4EBwd7TCJyhgIbwvkPmfOrnoHs49bWIyKSr8oDy4ABAzhw4ADp6enuZX/++Sd2u51mzZoB0K9fP1as8Hzd/fLly+nXr19VlyciJztnPIREQ1oC/PiG1dWIiAAVCCzp6enExcURFxcHQHx8PHFxcezZY76qfsqUKdx6663u9jfddBONGjVi7NixbN26ldWrV/PAAw8wbtw4AgICAJg0aRLLli3jhRde4I8//mDatGnExsZy1113VcIhiki5OP1g0CPm/JqX4MQxa+sREaECgSU2NpaePXvSs2dPACZPnkzPnj2ZOnUqAAkJCe7wAhAUFMTy5ctJTk6md+/ejBo1iuHDh/PKK6+42/Tv35/333+fN998k+7du/Pxxx+zZMkSunTpcqbHJyIV0e0GCDsLMlNg9fNWVyMicmbjsHgTjcMiUsn+/Abevw7sTrhjHTRpb3VFIlILec04LCJSQ7W/2Hw5oisXlj0EteP/24hIDaXAIiKlu2Q6OHxh50r44yurqxGROkyBRURK16hN4XuG/jsFcio+dpKIyJlQYBGRUzv3PqgfBcl74IdXra5GROooBRYROTW/ILj4SXN+7Stw/Ki19YhInaTAIiKn1/lqCO8K2Wmw7jWrqxGROkiBRUROz26HQVPM+fWzIeOItfWISJ2jwCIiZdPhUojsDjkZsOZFq6sRkTpGgUVEysZmgwvNEa358U04Gm9tPSJSpyiwiEjZtb0IWl8Aedmw4p9WVyMidYgCi4iUnc0GQ54EbPDbp7Av1uqKRKSOUGARkfKJ7AbdR5rz3/yfhuwXkWqhwCIi5Xfh/4HTH/as05D9IlItFFhEpPxCmkK/ieb88qmQl2NtPSJS6ymwiEjFDLgHAhvD0Z0QO8/qakSkllNgEZGK8Q+GCx425797BjJTrK1HRGo1BRYRqbheY6BROzh+BNa8ZHU1IlKLKbCISMU5fGDIE+b8+lmQvNfaekSk1lJgEZEz0+FSaDEAcjNh5VNWVyMitZQCi4icGZsNLn7SnP/lQzgQZ2k5IlI7KbCIyJlr2gu6XAsYGrJfRKqEAouIVI4L/w9sdti5AhJ+troaEallFFhEpHI0bAWdrzbn17xsaSkiUvsosIhI5Rl4j/m5dQkc2WllJSJSyyiwiEjliegKbYeA4YINb1hdjYjUIgosIlK5YiaYn798CDmZ1tYiIrWGAouIVK42gyC4KWQmwza9yVlEKocCi4hULrsDetxkzm/6j7W1iEitocAiIpWvILDsWgUp+ywtRURqBwUWEal8DVubw/VjmH1ZRETOkAKLiFSNgqssce+DYVhbi4jUeAosIlI1zroSfALhyA7Y95PV1YhIDVfuwLJ69WqGDx9OVFQUNpuNJUuWnLL9qlWrsNlsxabExER3m2nTphVb37Fjx3IfjIh4Eb/6ZmgBiHvP2lpEpMYrd2DJyMige/fuzJw5s1zbbdu2jYSEBPcUFhbmsb5z584e69esWVPe0kTE2xTcFtryKZw4Zm0tIlKjOcu7wbBhwxg2bFi5fygsLIzQ0NDSC3E6iYiIKPd+RcSLtRgIDVrBsXj4d0u4bgF0HmF1VSJSA1VbH5YePXoQGRnJkCFDWLt2bbH127dvJyoqitatWzNq1Cj27Nlzyv1lZWWRmprqMYmIl7Hb4ZJnCr+vecm6WkSkRqvywBIZGcns2bP55JNP+OSTT4iOjuaCCy5g06ZN7jYxMTHMnz+fZcuWMWvWLOLj4zn33HNJS0srdb/Tp08nJCTEPUVHR1f1oYhIRXS4BLpcY84fjddw/SJSITbDqPjzhjabjcWLFzNixIhybXf++efTvHlz/vOfkkfBTE5OpkWLFrz44ouMHz++xDZZWVlkZWW5v6emphIdHU1KSgrBwcHlqkdEqpgrD17uBqn7YMiTMOAfVlckIl4iNTWVkJCQ0/79tuSx5j59+rBjx45S14eGhtK+fftTtvHz8yM4ONhjEhEvZXfAefeZ88sfg6St1tYjIjWOJYElLi6OyMjIUtenp6ezc+fOU7YRkRrm7NGF83OHajA5ESmXcj8llJ6e7nHlIz4+nri4OBo2bEjz5s2ZMmUK+/fv55133gHg5ZdfplWrVnTu3JnMzEzefvttVq5cyTfffOPex/3338/w4cNp0aIFBw4c4PHHH8fhcDBy5MhKOEQR8Qp2Bwy81+x4m5UKPy+EHvp3XETKptyBJTY2lkGDBrm/T548GYDRo0czf/58EhISPJ7wyc7O5r777mP//v0EBgbSrVs3vv32W4997Nu3j5EjR3LkyBGaNGnCwIEDWb9+PU2aNDmTYxMRbzN4GvjWg5VPmVOXa8Dpa3VVIlIDnFGnW29S1k47ImKxnEyY0Q3Sk+DK16HnKKsrEhELeXWnWxGpw3z8oe+d5vzal8HlsrQcEakZFFhEpPr1Hgd+wXD4T9g4z+pqRKQGUGARkernHww9bzbnl0+F3Gxr6xERr6fAIiLWGPJPsNkhOx0ObLa6GhHxcgosImINhw90usKc//kDa2sREa+nwCIi1on5u/kZ9x6kJlhbi4h4NQUWEbFOi/7QvB/kZcP8y/RiRBEplQKLiFhr0KPm59GdsONba2sREa+lwCIi1mp1LnS93pyPe9/aWkTEaymwiIj1Bt4LNgds+wqSfrO6GhHxQgosImK98LOg46Xm/E9vW1uLiHglBRYR8Q4xE8zPTf+B5L3W1iIiXkeBRUS8Q8uB0PJccOWYb3KuHe9lFZFKosAiIt6j4ImhXxbCpnesrUVEvIoCi4h4jxb94IJHzPnVz+sqi4i4KbCIiHfpfzf41IOUPbBzZcX2kXEENs6HzNRKLU1ErKPAIiLexTew8E3OXz9YsTc5f3ADfDEJvvhH5dYmIpZRYBER73Pho1AvDI7sqNiLEff9ZH7+trhy6xIRyyiwiIj38Q+BAZPM+eVT4fhRa+sREcspsIiId4r5O4R1hsxk+P4Fq6sREYspsIiId3L4wMX/NOc3vAFHd1lbj4hYSoFFRLxXm4vMyZVj3hoSkTpLgUVEvJfNBkP/Zb4Y8fcvIP57qysSEYsosIiIdwvrBL3HmvP/fQRcedbWIyKWUGAREe93wSPgFwKJv0Dc+1ZXIyIWUGAREe9XrxGc/6A5v+KfkJVmbT0iUu0UWESkZujzN2jYGjIOwpqXrK5GRKqZAouI1AxOX7j4KXP+h9fg2F/W1iMi1UqBRURqjg6XQqvzIC8Lvp1Wtm0SfqnSkkSkeiiwiEjNYbPB0KcBG/z2KexZf/pt3jgXju02X4Z4eEfl1mMYZiDKyazc/YpIMQosIlKzRHSFs281579+EPJyT7/NjO6wcT4sGF65tfzyoRmIPrihcvcrIsUosIhIzXPh/5kvSEz4GX56q+zbpR2o3Dpi55mfu1ZV7n5FpJhyB5bVq1czfPhwoqKisNlsLFmy5JTtV61ahc1mKzYlJiZ6tJs5cyYtW7bE39+fmJgYfvzxx/KWJiJ1RVAYDH7CnF/5FKTss6aOgNDCeZfLvEUkIlWi3IElIyOD7t27M3PmzHJtt23bNhISEtxTWFiYe92HH37I5MmTefzxx9m0aRPdu3dn6NChHDx4sLzliUhdcfZoiO4L2emw9MGyb+dyVV4N/iGF86/1gg9vrrx9i4iHcgeWYcOG8dRTT3HVVVeVa7uwsDAiIiLck91e+NMvvvgit99+O2PHjuWss85i9uzZBAYGMnfu3PKWJyJ1hd0Ow18GuxO2fQW/f1m27bIrcdA5v+DC+aO74I8y1iAi5VZtfVh69OhBZGQkQ4YMYe3ate7l2dnZbNy4kcGDBxcWZbczePBg1q1bV+r+srKySE1N9ZhEpI4J6wQDJpnzSx+AzJTTb1OWNmVV9ApLgbycytu/iLhVeWCJjIxk9uzZfPLJJ3zyySdER0dzwQUXsGnTJgAOHz5MXl4e4eHhHtuFh4cX6+dS1PTp0wkJCXFP0dHRVXocIuKlznvAHAE37UDZxmZ5uSskba2c33b4Fl+m1waIVIkqDywdOnTg73//O7169aJ///7MnTuX/v3789JLZza09pQpU0hJSXFPe/furaSKRaRG8QmA4TPM+di5sHvN6bf5/O7K+W1XCY9UK7CIVAlLHmvu06cPO3aYAzg1btwYh8NBUlKSR5ukpCQiIiJK3Yefnx/BwcEek4jUUa3OMzvhAiy54/Ttj+2unN8tKbBkp1fOvkXEgyWBJS4ujsjISAB8fX3p1asXK1ascK93uVysWLGCfv36WVGeiNREQ/4JQRGQvOf0bY8frpzf1BUWkWpT7sCSnp5OXFwccXFxAMTHxxMXF8eePeZ/JKZMmcKtt97qbv/yyy/z2WefsWPHDrZs2cI999zDypUrmThxorvN5MmTeeutt1iwYAG///47d9xxBxkZGYwdO/YMD09E6oyAULjsBc9lIxeW3v6lrnAi+cx+05VXfJkCi0iVcJZ3g9jYWAYNGuT+PnnyZABGjx7N/PnzSUhIcIcXMJ8Cuu+++9i/fz+BgYF069aNb7/91mMfN9xwA4cOHWLq1KkkJibSo0cPli1bVqwjrojIKXW6HJr3gz3roPc46DAMwjrDwd+Kt03ZA/9uAY8dAUe5/1No0hUWkWpjM4zaMTRjamoqISEhpKSkqD+LSF2WlQ6/LIROV0JQE/jmMfjhldLb370JGrWp2G99dR/89LbnsuEzoNeYiu1PpA4q699vvUtIRGoXvyA45zYzrABcMMW8VdR3YsntC/q87FkP74yAv34o+2+VdIXl+JFylSsiZaPAIiK1m2+gGWDaXli4bMCkwkHfUvaa7wCaOxR2/Q/++0jZ911SYFnxTzP45GadUdki4kmBRUTqhjYXwbn3w9VvmU8Udb7aXL5uJrzUpbDdgc3wv6fLFjhK6nQLZvDZvvzMaxYRtwr2NBMRqWFsNrjoscLvPW+BuPfh0B/F2373b7DZ4YKHT73Pkq6wFDAq8SWLIqIrLCJSRzXrBYOmlL7+51M8El3gVIFFA8iJVCoFFhGpu2ImFM63HwYX/6vw+7F42L22+DZFnSqwnDh2ZrWJiAcFFhGpu3wCoMOl5vx590NIM8/18y899fYn92EZ/UXh/PGjZ16fiLgpsIhI3XbNHHMslma9IaBB+bY9+QpLy3Ph/IfM+RMKLCKVSYFFROo238DCgeNaDIB2Qz3X5+WUvu3JgcVmg4CG5ryusIhUKgUWEZECDieM+gimHgO7j7ksLaH09iU91hyYH1h0hUWkUimwiIiczG6Hhq3N+f2bSm9XUmApuK10XJ1uRSqTAouISEnaX2x+bv+m9DYlPSUUUMoVlsRfTx1+ROSUFFhEREoSHWN+Htxa8vq0RNi7vvjywPwrLEUfa87LhdkD4a1BkJlauXWK1BEKLCIiJWncwfw8vB1cJYxau+blkrcruMKScxxyMvPnMwrXZxyqtBJF6hIFFhGRkjRsBc4Ac8Tad6+G1AOe67NKuVLiHwIOP3O+4E3QBcEF9FJEkQpSYBERKYnDB4bPMEPLrv/Bm4Pg4O+n385mg+g+5vyuVeZnzvHC9RqyX6RCFFhERErT/QaY8D006QTpiTD7XFj6IGSmmFNp2ueP5bLuNTAMyDlRuK60KzMickoKLCIip9K4HYz5CtoOBlcO/PgGzOwLf3zp2e6sEYXzvceZ47gk/2VOuUUCizrdilSI0+oCRES8Xr1GcPMn5i2eL++Fo7sK1131JtSPKLwNBOBbD8I7Q0IcJPwMgY0K12WlVVfVIrWKrrCIiJRV6wtgwhqI7FG4rNV50Pp880WKRUV0NT/jPoDUIqPlKrCIVIgCi4hIefjWMwNKgaCwkts1bm9+/vk1fHpb4fJT9X0RkVIpsIiIlFd038J5u6PkNgWB5WQp+yq/HpE6QH1YRETKq8MwGPo0hHcpvU3BG6BPdiy+amoSqeUUWEREystmg34TT92mfmTJy/esg50rYV8sdL4aGret/PpEaiEFFhGRquAXVPq6/1xlfm5cAPf8ar4dWkROSf+WiIhUtYatYcAkGLvMc3nqPvjPlZCbbU1dIjWIAouISFUJbGx+9r8bhvwTWvSDjpd7tolfDbFzqr82kRpGt4RERKrK31ebfVY6X1W4bMTrsLYjtBsCib/C0vvhpzkQM8HsGyMiJdIVFhGRqhLSFLpe6/nos38IXPQYNO8L3W8En3pwZDusmg6uPOtqFfFyCiwiIlbxqw+9xpjz3/0blk+1tBwRb6bAIiJipSFPwMDJ5vz6WbDhTUg/ZG1NIl5IgUVExEoOHxj8OHS7EYw8+PoBeKEDLLnT7OMiIgDYDMMwrC6iMqSmphISEkJKSgrBwcEltnG5XGRn6/FBqTo+Pj44HKUM1S5yKnk55hWWXxdB4i/mMpsdLnzMfMrI4WNtfSJVpCx/v6ECgWX16tU899xzbNy4kYSEBBYvXsyIESPKtO3atWs5//zz6dKlC3Fxce7l06ZN44knnvBo26FDB/74448y13W6A87OziY+Ph6Xy1XmfYpURGhoKBEREdj0xIdU1J4NsHYGbPvK/N6wDVw0Fc66Uk8SSa1T1sBS7seaMzIy6N69O+PGjePqq68u83bJycnceuutXHTRRSQlJRVb37lzZ7799tvCwpyV98S1YRgkJCTgcDiIjo7GrlElpQoYhsHx48c5ePAgAJGRpQzNLnI6zWMg+j3Y/B/49gk4uhMWjYaontD/H9BpuK64SJ1T7lQwbNgwhg0bVu4fmjBhAjfddBMOh4MlS5YUL8TpJCIiotz7LYvc3FyOHz9OVFQUgYGBVfIbIgABAQEAHDx4kLCwMN0ekoqz2eDsW80xXH54DX54FQ5sho/HQv0oOGc89BoL9RpZXalItaiWSw3z5s1j165dPP7446W22b59O1FRUbRu3ZpRo0axZ8+eU+4zKyuL1NRUj6k0eXnm2Aa+vr4VOwCRcigIxTk5ORZXIrWCX30YNAUm/QznPwz1wiDtAKx8El46Cz7/Bxz83eoqRapclQeW7du38/DDD/Puu++WepsnJiaG+fPns2zZMmbNmkV8fDznnnsuaWlppe53+vTphISEuKfo6OjT1qI+BVId9M+ZVImgJmZwuXcLXPUGRHaH3EzYtABe7wsLroDfFuu9RFJrVenQ/Hl5edx000088cQTtG/fvtR2RW8xdevWjZiYGFq0aMFHH33E+PHjS9xmypQpTJ482f09NTW1TKFFRKRGc/qZI+R2u8Ec9n/96/DHVxD/nTkFNoaeo+Ds0dCojdXVilSaKg0saWlpxMbGsnnzZu666y7AfLTYMAycTifffPMNF154YbHtQkNDad++PTt27Ch1335+fvj5+VVZ7SIiXs1mgxb9zenYX7DpHbOTbnqS+YTR2hnQ6jxzJN2Ol5tBR6QGq9JbQsHBwfz666/ExcW5pwkTJtChQwfi4uKIiYkpcbv09HR27txZ55+yGDNmTImPjK9atQqbzUZycjKZmZmMGTOGrl274nQ6y/yIeYH58+djs9m45JJLPJYnJydjs9lYtWqVe5nNZiuxwzRQKXWEhoaWuv7QoUPccccdNG/eHD8/PyIiIhg6dChr1651n49TTatWrXIfa6dOnYrtf9GiRdhsNlq2bOmxfNWqVZx99tn4+fnRtm1b5s+fX67jEqkWDVqY7ye69ze44T1oOwSwmW+C/ngcPNsGPh4PWz+D7AyrqxWpkHJfYUlPT/e48hEfH09cXBwNGzakefPmTJkyhf379/POO+9gt9vp0qWLx/ZhYWH4+/t7LL///vsZPnw4LVq04MCBAzz++OM4HA5Gjhx5BodWN+Tl5REQEMA//vEPPvnkkwrtw+l08u233/K///2PQYMGWVbHqVxzzTVkZ2ezYMECWrduTVJSEitWrODIkSNccsklJCQkuNtOmjSJ1NRU5s2b517WsGFDdu/eTb169Th48CDr1q2jX79+7vVz5syhefPmHr8ZHx/PZZddxoQJE3jvvfdYsWIFt912G5GRkQwdOrTSj1HkjDl8oNPl5pS8Bza/a06p+2HLx+bk9Ie2g81Ho9sPhYAGVlctUiblDiyxsbEef9QK+pGMHj2a+fPnk5CQcNonfE62b98+Ro4cyZEjR2jSpAkDBw5k/fr1NGnSpLzl1Tn16tVj1qxZgDkwX3JycoX2cf311/Pwww+zYcMGy+ooTXJyMt9//z2rVq3i/PPPB6BFixb06dPH3aboI/EBAQFkZWWV+Ji80+nkpptuYu7cue7Asm/fPlatWsW9997LBx984G47e/ZsWrVqxQsvvABAp06dWLNmDS+99JICi3i/0OYw6BHzyaL9G+H3z+D3L+DYbvjjS3OyO83bRp2Gm7eNgsKsrlqkVOUOLBdccAGnGhz3dJfMp02bxrRp0zyWLVy4sLxlnBHDMDiRY81r3AN8HF75FMm0adNo27YtH3/8Mddee63V5XgICgoiKCiIJUuW0Ldv3zPuuzRu3DguuOACZsyYQWBgIPPnz+eSSy4hPDzco926desYPHiwx7KhQ4dyzz33nNHvi1Qrux2izzGnIU9C0hYzuPz+BRzcCjtXmtOXk6F5PzO8dLrcDDwiXqRKO916qxM5eZw19b+W/PbWfw4l0Lfsp/3LL78kKCjIY1nBuDKVKSoqikmTJvHoo4+Wu/9JVXM6ncyfP5/bb7+d2bNnc/bZZ3P++edz44030q1bt3Lvr2fPnrRu3ZqPP/6YW265hfnz5/Piiy+ya9cuj3aJiYnFQkx4eDipqamcOHHCPUicSI1hs0FEV3Ma9Agc3gG/f26GlwObYM8P5vTfKRB2FrS9yLx91LyfOu2K5TRGvZcbNGiQR6fluLg43n777Sr5rYceeohDhw4xd+7cKtn/mbjmmms4cOAAn3/+OZdccom7M2xFO8GOGzeOefPm8d1335GRkcGll15auQWL1ASN28K5k+Fv/4N7tsAl/4YWA82XLh7cao6u+86V8O+W8P4N8ONbcDTe6qqljqqTV1gCfBxs/ac1fRACfMo3VHu9evVo27atx7J9+/ZVZkluoaGhTJkyhSeeeILLL7+8Sn7jTPj7+zNkyBCGDBnCY489xm233cbjjz/OmDFjyr2vUaNG8eCDDzJt2jRuueWWEgc1jIiIKPbeq6SkJIKDg3V1RWqf0GjoO8Gcjh+FXf+DHStgx7fmo9J/LjMnMF/G2PoCs/9Ly3P1egCpFnUysNhstnLdlqlL7r77bl555RVmzJhhdSmnddZZZ5X6mPXpNGzYkCuuuIKPPvqI2bNnl9imX79+LF261GPZ8uXLPZ4uEqmVAhtCl2vMyTAg8VczuOxYAXvXmy9jPLoTYueY7cO7mOGl1XnmuDD+IdbWL7WS/mrXAlu3biU7O5ujR4+SlpZGXFwcAD169Cj3vvz9/XniiSeYOHFiiesLHmMvql27dtSrV++M68jLyyu2bz8/P8LCwrjuuusYN24c3bp1o379+sTGxvLss89y5ZVXlvMIC82fP5/XX3+dRo1K/n+HEyZM4LXXXuPBBx9k3LhxrFy5ko8++oivvvqqwr8pUuPYbBDZzZzOnQyZqbD7e3OMl/jv4eBvZkfepC3mqLs2u/lW6VbnQcuB0KwP+AdbfRRSCyiw1AKXXnopf/31l/t7z549AU75NNepjB49mhdeeIGtW7cWW1f0dQgFvv/+ewYOHHjGdaSnp7u3KdCmTRt+++03YmJieOmll9i5cyc5OTlER0dz++2388gjj5Tn0DwEBASc8tZOq1at+Oqrr7j33nuZMWMGzZo14+2339YjzVK3+QdDx8vMCSD9UJEAs9q88rJ/ozmteckMMOFdzI67zfuan8F1e1BQqRibUdG/al4mNTWVkJAQUlJSCA72TPOZmZnEx8fTqlUr/P39LapQ6gr98yZ1Wso+88pL/Gr4ay0k/1W8TYOWRQJMf2jczrySI3XSqf5+F6UrLCIiUnlCmkGPkeYEkHoA9qw3X9S4Zx0kbjEHrzu2G37OH6gxoAE07QVNe0Oz3uZ8YEOrjkC8lAJLLde5c2eP2zRFvfHGG4waNapO1SEi1Sw4CrpcbU4AmSmw7yf4a50ZZPbHwolj+Z16vy3crmHrIgGmtzl2jNPXmmMQr6DAUsstXbqUnJycEtedPChaXahDRCzmH2IORtc2fxTp3GxI+hX2bTTDy77Y/KeQdpnTrx+Z7Ry+ENHNDDCRPSCyOzRuDw79Gasr9L90LdeiRQurSwC8pw4R8TJO3/zbQb2Av5nLjh+F/ZsKA0zBVZj9+fPubQMgoosZXgpCTJOOuhJTSymwiIiIdwlsCO0GmxOYY8Ec3VX49FHCL5D4C2Snm7eX9v1UuK3D13ytQFSP/CDTHcI6g486wNd0CiwiIuLdbDZo1Macul1vLnO5zFtHCT9DQhwciDODTFaK+T0hrsj2DmjUFsI7509dzCszwU31dFINosAiIiI1j91uPg7duB10zX/DvGGYTx8VhJiEn80gc+IoHN5mTr99WrgP/xAzvBQNMmGdwLeeBQckp6PAIiIitYPNBg1bmVPnEeYyw4C0REgqGJH3N3M6vM18YumvteZUuBNz+6IBpkknc5nDx4qjknwKLCIiUnvZbObIusGRhX1iwHw66fCfha8VKAgy6UmFTyj9/kVhe7uPeTWnSQczwDTpYIaZhq0VZKqJAouIiNQ9Tl+zH0tEF8/l6Yfy34/0mznI3aE/4NA2yMmAg1vNicWF7e1Os39Mk47mFJb/2bCNnlaqZHarC5DSjRkzhhEjRhRbvmrVKmw2G8nJyezevRubzVZsWr9+fZl+Y9q0adhsNiZMmOCxPC4uDpvNxu7duwHcv3PyywkLfPrppwwZMoQmTZoQHBxMv379+O9//3vGx1rg559/5oorriAsLAx/f39atmzJDTfcwMGDB93HcKqp4DdKOlaAiRMnYrPZGDNmjHvZ6tWrGT58OFFRUdhstgq/GVpEapCgJtD6Aug3Ea6aBX/7H0zZB/f8CjctgiFPQo9R5mPYvkHgyjVDzdYl8N0zsGgMvN4Xno6E1/rAh7fAiifh54XmE06ZqRYfYM2lKyy1xLfffkvnzp3d30t7A3FJ/P39mTNnDvfddx/t2rWr0O+vXr2aIUOG8PTTTxMaGsq8efMYPnw4GzZsKPZCw/I6dOgQF110EZdffjn//e9/CQ0NZffu3Xz++edkZGRw//33e4SQc845h7/97W/cfvvtxfYVHR3NwoULeemll9wvPszMzOT999+nefPmHm0zMjLo3r0748aN4+qrrz6jYxCRGsxuh9Dm5tT+4sLlhmG+O+nQNjj0uxlcDuZfkclOK+zoe7KgcHPQu0ZtzdtMjfI7D4c2B7uj+o6rhlFgqSUaNWpEREREhbbt0KEDYWFhPProo3z00UcV2sfLL7/s8f3pp5/ms88+44svvjjjwLJ27VpSUlJ4++23cTrNf2RbtWrFoEGD3G2CgoLc8w6Hg/r165d4Ps4++2x27tzJp59+6n4dwKeffkrz5s1p1aqVR9thw4YxbNiwM6pdRGoxmw1Co82paP8Yw4DU/YUB5sh2OLzD/ExPKpx2f++5P4ef2Semcdv8QJMfZBq1hYDQaj00b1Q3A4thQM5xa37bJ7BKnvu/4ooryMzMpH379jz44INcccUV5dr+mWee4ZxzziE2NpbevXufcT0ul4u0tDQaNjzzF5hFRESQm5vL4sWLufbaa923eCpq3LhxzJs3zx1Y5s6dy9ixY1m1atUZ1yoigs1mvgQypFnhKwgKZKYUhpfD282Ov0d2wJGdkJeVf6Xm9+L7rNfEDDMeUyto0KrOvCiybgaWnOPwdJQ1v/3IgXI94//ll196XD0AyMvLc88HBQXxwgsvMGDAAOx2O5988gkjRoxgyZIl5QotZ599Ntdffz0PPfQQK1asKPN2pXn++edJT0/n+uuvP+N99e3bl0ceeYSbbrqJCRMm0KdPHy688EJuvfXWCr2H6Oabb2bKlCnulzGuXbuWhQsXKrCISNXzD4FmvcypKFcepOzNDzHbiwSa7ZCeCBmHzGnvhhL2GVpCmMkPNPWa1JrB8epmYKlBBg0axKxZszyWbdiwgZtvvhmAxo0bM3nyZPe6c845hwMHDvDcc8+V+yrLU089RadOnfjmm28ICwurcM3vv/8+TzzxBJ999tkZ7aeof/3rX0yePJmVK1eyYcMGZs+ezdNPP83q1avp2rVrufbVpEkTLrvsMubPn49hGFx22WU0bty4UuoUEakQuwMatDSndkM812WmFj5qfXQXHI0vnE9PhMxkOLDJnE7mG5R/JaYlhLYwpwYtCvvk1KBB8upmYPEJNK90WPXb5VCvXj3atm3rsWzfvn2n3CYmJobly5eXu7Q2bdpw++238/DDDzNnzpxybw+wcOFCbrvtNhYtWsTgwYNPv0E5NGrUiOuuu47rrruOp59+mp49e/L888+zYMGCcu9r3Lhx3HXXXQDMnDmzUusUEalU/sHmu5GiehRfl51hju7rEWjyQ03KPvN9S4m/mlNJAhvnB5j8EOMOMy3NW1pe9A6muhlYbLYalSrLKy4ujsjIyAptO3XqVNq0acPChQvLve0HH3zAuHHjWLhwIZdddlmFfr+sfH19adOmDRkZGRXa/pJLLiE7OxubzcbQoUMruToRkWriW6/w1QIny8mE5D3mO5eO/WXOJ/9lTsf2mO9dOn7YnPZvLHn/9SPzA0wLs3Nx3zuhnjVXpOtmYKlFFixYgK+vr/tJnE8//ZS5c+fy9ttvV2h/4eHhTJ48meeee67E9du2FX9Er3PnzixatIjRo0czY8YMYmJiSExMBCAgIICQkJAy/XZKSkqxcV4aNWrEzz//zMKFC7nxxhtp3749hmHwxRdfsHTpUubNm1e+A8zncDj4/fff3fMlSU9PZ8eOHe7v8fHxxMXF0bBhw2KPQIuIeB0ff2jS3pxKciI5P8DsOSnQ5H/PyYC0BHMq6DvT52/VVv7JFFhqgSeffJK//voLp9NJx44d+fDDD7n22msrvL/777+fWbNmkZmZWWzdjTfeWGzZ3r17efPNN8nNzWXixIlMnDjRvW706NHMnz+/TL+7atWqYo9Ajx8/nkceeYTAwEDuu+8+9u7di5+fH+3atePtt9/mlltuKd/BFREcHHzK9bGxsR6PThf0FSrPMYmIeK2AUHOK7F58nWHA8aOQvLswwKTuh3qV0y+xImyGYRiW/XolSk1NJSQkhJSUlGJ/iDIzM4mPj6dVq1b4+3vP/TipnfTPm4hI2Z3q73dRGppfREREvJ4CSy0XFBRU6vT999+ffgeVYM+ePaesY8+ePdVSh4iI1Fzqw1LLlfayQoCmTZtWSw1RUVGnrCMqyqJB/EREpMZQYKnlTh7DxQpOp9Mr6hARkZqr3LeEVq9ezfDhw4mKisJms7FkyZIyb7t27VqcTic9evQotm7mzJm0bNkSf39/YmJi+PHHH8tbmoiIiNRS5Q4sGRkZdO/evdyjgyYnJ3Prrbdy0UUXFVv34YcfMnnyZB5//HE2bdpE9+7dGTp0KAcPHixveadUSx6IEi/ncrmsLkFEpNY5o8eabTYbixcvZsSIEadte+ONN9KuXTscDgdLlizx6NMQExPDOeecw2uvvQaY/8GPjo7m7rvv5uGHHy5TLad6LCovL4/t27cTGBhIkyZNzvhtvyIlMQyD7OxsDh06RF5eHu3atcNuV792EZFTKetjzdXSh2XevHns2rWLd999l6eeespjXXZ2Nhs3bmTKlCnuZXa7ncGDB7Nu3bpS95mVlUVWVpb7e2pqaqltHQ4HzZo1Y9++fezevbviByJSBoGBgTRv3lxhRUSkElV5YNm+fTsPP/ww33//PU5n8Z87fPgweXl5hIeHeywPDw/njz/+KHW/06dP54knnihzHUFBQbRr146cnJyyFy9STg6HA6fTqat4IiKVrEoDS15eHjfddBNPPPEE7duX8i6DCpoyZYp7qHQwr7BER0efchuHw1Hqe2NERETEe1VpYElLSyM2NpbNmzdz1113AWb/FMMwcDqdfPPNNwwcOBCHw0FSUpLHtklJSURERJS6bz8/P/z8/KqyfBEREfESVXqTPTg4mF9//ZW4uDj3NGHCBDp06EBcXBwxMTH4+vrSq1cvVqxY4d7O5XKxYsUK+vXrV5XliYiISA1R7iss6enp7Nixw/09Pj6euLg4GjZsSPPmzZkyZQr79+/nnXfewW6306VLF4/tw8LC8Pf391g+efJkRo8eTe/evenTpw8vv/wyGRkZjB079gwOTURERGqLcgeW2NhYBg0a5P5e0I9k9OjRzJ8/n4SEhHK/G+aGG27g0KFDTJ06lcTERHr06MGyZcuKdcQ9lYKns0/1tJCIiIh4l4K/26cbZeWMxmHxJvv27Tttp1sRERHxTnv37qVZs2alrq81gcXlcnHgwAHq169fqY+UFjx9tHfv3lMOaCNnRue5+uhcVw+d5+qh81x9qupcG4ZBWloaUVFRpxy/qta8/NBut58ymZ2p4OBg/ctQDXSeq4/OdfXQea4eOs/VpyrOdUhIyGnbaChOERER8XoKLCIiIuL1FFhOw8/Pj8cff1yD1FUxnefqo3NdPXSeq4fOc/Wx+lzXmk63IiIiUnvpCouIiIh4PQUWERER8XoKLCIiIuL1FFhERETE6ymwnMbMmTNp2bIl/v7+xMTE8OOPP1pdUo0xffp0zjnnHOrXr09YWBgjRoxg27ZtHm0yMzOZOHEijRo1IigoiGuuuYakpCSPNnv27OGyyy4jMDCQsLAwHnjgAXJzc6vzUGqUZ555BpvNxj333ONepvNcefbv38/NN99Mo0aNCAgIoGvXrsTGxrrXG4bB1KlTiYyMJCAggMGDB7N9+3aPfRw9epRRo0YRHBxMaGgo48ePJz09vboPxWvl5eXx2GOP0apVKwICAmjTpg1PPvmkx7tmdJ4rZvXq1QwfPpyoqChsNhtLlizxWF9Z5/WXX37h3HPPxd/fn+joaJ599tkzL96QUi1cuNDw9fU15s6da/z222/G7bffboSGhhpJSUlWl1YjDB061Jg3b56xZcsWIy4uzrj00kuN5s2bG+np6e42EyZMMKKjo40VK1YYsbGxRt++fY3+/fu71+fm5hpdunQxBg8ebGzevNlYunSp0bhxY2PKlClWHJLX+/HHH42WLVsa3bp1MyZNmuRervNcOY4ePWq0aNHCGDNmjLFhwwZj165dxn//+19jx44d7jbPPPOMERISYixZssT4+eefjSuuuMJo1aqVceLECXebSy65xOjevbuxfv164/vvvzfatm1rjBw50opD8kr/+te/jEaNGhlffvmlER8fbyxatMgICgoyZsyY4W6j81wxS5cuNR599FHj008/NQBj8eLFHusr47ympKQY4eHhxqhRo4wtW7YYH3zwgREQEGC88cYbZ1S7Assp9OnTx5g4caL7e15enhEVFWVMnz7dwqpqroMHDxqA8d133xmGYRjJycmGj4+PsWjRIneb33//3QCMdevWGYZh/stlt9uNxMREd5tZs2YZwcHBRlZWVvUegJdLS0sz2rVrZyxfvtw4//zz3YFF57nyPPTQQ8bAgQNLXe9yuYyIiAjjueeecy9LTk42/Pz8jA8++MAwDMPYunWrARg//fSTu83XX39t2Gw2Y//+/VVXfA1y2WWXGePGjfNYdvXVVxujRo0yDEPnubKcHFgq67y+/vrrRoMGDTz+2/HQQw8ZHTp0OKN6dUuoFNnZ2WzcuJHBgwe7l9ntdgYPHsy6dessrKzmSklJAaBhw4YAbNy4kZycHI9z3LFjR5o3b+4+x+vWraNr166Eh4e72wwdOpTU1FR+++23aqze+02cOJHLLrvM43yCznNl+vzzz+nduzfXXXcdYWFh9OzZk7feesu9Pj4+nsTERI9zHRISQkxMjMe5Dg0NpXfv3u42gwcPxm63s2HDhuo7GC/Wv39/VqxYwZ9//gnAzz//zJo1axg2bBig81xVKuu8rlu3jvPOOw9fX193m6FDh7Jt2zaOHTtW4fpqzcsPK9vhw4fJy8vz+A84QHh4OH/88YdFVdVcLpeLe+65hwEDBtClSxcAEhMT8fX1JTQ01KNteHg4iYmJ7jYl/W9QsE5MCxcuZNOmTfz000/F1uk8V55du3Yxa9YsJk+ezCOPPMJPP/3EP/7xD3x9fRk9erT7XJV0Loue67CwMI/1TqeThg0b6lzne/jhh0lNTaVjx444HA7y8vL417/+xahRowB0nqtIZZ3XxMREWrVqVWwfBesaNGhQofoUWKRaTJw4kS1btrBmzRqrS6l19u7dy6RJk1i+fDn+/v5Wl1OruVwuevfuzdNPPw1Az5492bJlC7Nnz2b06NEWV1d7fPTRR7z33nu8//77dO7cmbi4OO655x6ioqJ0nusw3RIqRePGjXE4HMWepEhKSiIiIsKiqmqmu+66iy+//JL//e9/NGvWzL08IiKC7OxskpOTPdoXPccREREl/m9QsE7MWz4HDx7k7LPPxul04nQ6+e6773jllVdwOp2Eh4frPFeSyMhIzjrrLI9lnTp1Ys+ePUDhuTrVfzciIiI4ePCgx/rc3FyOHj2qc53vgQce4OGHH+bGG2+ka9eu3HLLLdx7771Mnz4d0HmuKpV1XqvqvycKLKXw9fWlV69erFixwr3M5XKxYsUK+vXrZ2FlNYdhGNx1110sXryYlStXFrtE2KtXL3x8fDzO8bZt29izZ4/7HPfr149ff/3V41+Q5cuXExwcXOwPR1110UUX8euvvxIXF+eeevfuzahRo9zzOs+VY8CAAcUezf/zzz9p0aIFAK1atSIiIsLjXKemprJhwwaPc52cnMzGjRvdbVauXInL5SImJqYajsL7HT9+HLvd88+Tw+HA5XIBOs9VpbLOa79+/Vi9ejU5OTnuNsuXL6dDhw4Vvh0E6LHmU1m4cKHh5+dnzJ8/39i6davxt7/9zQgNDfV4kkJKd8cddxghISHGqlWrjISEBPd0/Phxd5sJEyYYzZs3N1auXGnExsYa/fr1M/r16+deX/C47cUXX2zExcUZy5YtM5o0aaLHbU+j6FNChqHzXFl+/PFHw+l0Gv/617+M7du3G++9954RGBhovPvuu+42zzzzjBEaGmp89tlnxi+//GJceeWVJT4W2rNnT2PDhg3GmjVrjHbt2tX5x22LGj16tNG0aVP3Y82ffvqp0bhxY+PBBx90t9F5rpi0tDRj8+bNxubNmw3AePHFF43Nmzcbf/31l2EYlXNek5OTjfDwcOOWW24xtmzZYixcuNAIDAzUY81V7dVXXzWaN29u+Pr6Gn369DHWr19vdUk1BlDiNG/ePHebEydOGHfeeafRoEEDIzAw0LjqqquMhIQEj/3s3r3bGDZsmBEQEGA0btzYuO+++4ycnJxqPpqa5eTAovNceb744gujS5cuhp+fn9GxY0fjzTff9FjvcrmMxx57zAgPDzf8/PyMiy66yNi2bZtHmyNHjhgjR440goKCjODgYGPs2LFGWlpadR6GV0tNTTUmTZpkNG/e3PD39zdat25tPProox6Pyeo8V8z//ve/Ev+7PHr0aMMwKu+8/vzzz8bAgQMNPz8/o2nTpsYzzzxzxrXbDKPI0IEiIiIiXkh9WERERMTrKbCIiIiI11NgEREREa+nwCIiIiJeT4FFREREvJ4Ci4iIiHg9BRYRERHxegosIiIi4vUUWERERMTrKbCIiIiI11NgEREREa+nwCIiIiJe7/8B+tTJ/EpLHe0AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            H1_NL1_LSTM0  H5_NL2_LSTM1\n",
              "accuracy %          20.0     58.888889"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5dd5f66a-d560-4c98-955a-f240ff2bb644\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>H1_NL1_LSTM0</th>\n",
              "      <th>H5_NL2_LSTM1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>accuracy %</th>\n",
              "      <td>20.0</td>\n",
              "      <td>58.888889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dd5f66a-d560-4c98-955a-f240ff2bb644')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5dd5f66a-d560-4c98-955a-f240ff2bb644 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5dd5f66a-d560-4c98-955a-f240ff2bb644');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"             index=test_accuracy_models\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"H1_NL1_LSTM0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 20.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"H5_NL2_LSTM1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 58.88888888888889,\n        \"max\": 58.88888888888889,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          58.88888888888889\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYjnCsbSm4x9"
      },
      "source": [
        "Notes:\n",
        "- Considerar usar un random_seed para quedarnos solo con los mejores resultados\n",
        "- En este nos interesa guardar solo el ultimo estado ya que ese estado contiene a su vez los otros anteriores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NWk4UCNY6IU"
      },
      "source": [
        "# Ex 2. Cryptoanalysis with corrupted messages using RNNs/LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuW-po5hsQqt"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Similar to the exercise solved on P2-examples, you have to solve time-series modelling based on Cryptanalysis.\n",
        "\n",
        "For this exercise, you have training.pkl and testing_corrupted.pkl files.\n",
        "These files contain a new encrypted dataset of 10000 sentences, 8000 for training and 2000 for the test.\n",
        "Similar to the exercise solved in class, all the samples are encrypted using the Vigenère cipher with\n",
        "7-length keyword. However, during the transmission of the test set, the encrypted data has been corrupted\n",
        "with a new char (\"-\"), while the training set has been transmitted correctly.\n",
        "\n",
        "Each 32-length sentence contains 4 corrupted chars randomly distributed on the test set, representing 12,5 % of total data.\n",
        "\n",
        "Example:\n",
        "\n",
        "Received Ciphertext:   'WCPS-VH-JHIKCUSETJV-AW-LPVUAHFHH'\n",
        "Correct Ciphertext (Not provided):   'WCPSEVHAJHIKCUSETJVKAWGLPVUAHFHH'\n",
        "Ground truth:   'HEWENTALLOUTANDGAVEITHISBESTSHOT'\n",
        "\n",
        "Steps :\n",
        "1. Discover the keyword used to encrypt the plaintext data. (hint: use Vigenère table and some samples)\n",
        "2. Design/Implement an strategy to train the model so that it can be robust to missing characters in the testing samples ( to be discussed in class )\n",
        "3. Train a sequential model to decode the corrupted test data.\n",
        "4. Evaluate the decoding accuracy for the test set in terms of characters that were not corrupted or corrupted independently.\n",
        "5. Try to improve the performance by applying some improvements over the model: stacked LSTMs,\n",
        "hidden_sizes, embedding_size, optimizer, data augmentation during training, etc...\n",
        "6. Visualize and discuss on the final results.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "717kp08em4x9"
      },
      "source": [
        "In 2. being robust means getting at least 87.5% accuracy (all non corrupt chars).\n",
        "\n",
        "For 3. we should have 2 losses, and 2 accuracies, 1 for normal chars, and 1 for corrupted chars. We should try to get 95% accuracy, 100% of the 87,5% correct chars and more or less 50% of corrupted chars are solved correctly.\n",
        "\n",
        "Advice: do data augmentation/transformation to try to make the training data look more like the testing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUEWLxMusKiE"
      },
      "source": [
        "# Sol 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6o7r20jm4x-"
      },
      "source": [
        "## 1. Discover the keyword used to encrypt the plaintext data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KpDXZqDia40H"
      },
      "outputs": [],
      "source": [
        "# Load train and test files into memory\n",
        "pkl_file = open(datadir+'train_vigenere.pkl', 'rb')\n",
        "train = pickle.load(pkl_file)\n",
        "pkl_file.close()\n",
        "\n",
        "pkl_file = open(datadir+'testing_corrupted.pkl', 'rb')\n",
        "test = pickle.load(pkl_file)\n",
        "pkl_file.close()\n",
        "\n",
        "vocabulary = [char for char in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'] # Predefined vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f5qf5wgdm4x-"
      },
      "outputs": [],
      "source": [
        "def int_to_vocabulary(message, vocabulary):\n",
        "  decoded = ''\n",
        "  for letter_code in message:\n",
        "    decoded += vocabulary[letter_code]\n",
        "  return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r984Et6Em4x-",
        "outputId": "fcc9b046-482d-49d5-b042-c623fc776042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Message encrypted:       FHXMWFOELYIAMGKZUJQSLROBROKWIAUL\n",
            "The keyword for en/decryption: MATRIXMATRIXMATRIXMATRIXMATRIXMA\n",
            "Train Message decrypted:       THEVOICESHADAGRIMMESSAGEFORFADIL\n",
            "\n",
            "The keyword (length 6) is: MATRIX\n"
          ]
        }
      ],
      "source": [
        "keyword = (train[0][0]-train[0][1]) % len(vocabulary)\n",
        "print(f'Train Message encrypted:       {int_to_vocabulary(train[0][0],vocabulary)}')\n",
        "print( 'The keyword for en/decryption: {kw}'.format(kw=int_to_vocabulary(keyword, vocabulary)))\n",
        "print(f'Train Message decrypted:       {int_to_vocabulary(train[0][1],vocabulary)}')\n",
        "print('\\nThe keyword (length {l}) is: {kw}'.format(l=6, kw=int_to_vocabulary(keyword, vocabulary)[:6]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "C_h1HGGCm4x_"
      },
      "outputs": [],
      "source": [
        "# LUCA: PONE EN EL ENUNCIADO QUE ES DE LENGTH 7 PERO MATRIX TIENE 6, ERROR DE ENUNCIADO?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8TD_2oRm4x_"
      },
      "source": [
        "## 2.Design/Implement an strategy to train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLAjbEqpm4x_"
      },
      "source": [
        "Proposed strategy: train as if there was another character in the vocabulary\n",
        "\n",
        "Problems of this strategy: this character won't be trained properly\n",
        "\n",
        "Solution to this problem: we could intentionally corrupt training data so the model learns how to interpret those appropiately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kzR4fuBDm4x_"
      },
      "outputs": [],
      "source": [
        "corr_vocab = [char for char in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ-'] # Corrupted vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I20FsCUdm4x_"
      },
      "outputs": [],
      "source": [
        "class CorruptedDataset(Dataset):\n",
        "    # the data is in the form [img_name, boundaries]\n",
        "    def __init__(self, data, p=0.125, corrupted_char=26):\n",
        "        self.data = data\n",
        "        self.corr_prob = p\n",
        "        self.corr_char = corrupted_char\n",
        "        self.shape = data.shape\n",
        "        self.batch_size = None\n",
        "\n",
        "        def corrupt_tensor(tensor):\n",
        "            corrupted_idx = np.random.uniform(size=tensor.shape[0]) < self.corr_prob\n",
        "            corr_item = tensor.clone()\n",
        "            corr_item[corrupted_idx==True] = self.corr_char\n",
        "            return corr_item\n",
        "        self.transform = corrupt_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "l8z-MpQDm4x_"
      },
      "outputs": [],
      "source": [
        "class DecrypterNetwork(nn.Module):\n",
        "  def __init__(self,\n",
        "               hidden_size : int = 8,\n",
        "               num_layers = 1,\n",
        "               num_letters = 26,\n",
        "               letters_embedding_size : int = 8,\n",
        "               use_lstm : bool = False):\n",
        "    # Define RNN or LSTM architecture\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_letters = num_letters\n",
        "    self.letters_embedder = torch.nn.Embedding(num_letters, letters_embedding_size)\n",
        "    self.use_lstm = use_lstm\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    if(use_lstm):\n",
        "      self.rnn =  nn.LSTM(input_size = letters_embedding_size, hidden_size = hidden_size,\n",
        "                          num_layers=num_layers, batch_first = True)\n",
        "    else:\n",
        "      self.rnn =  nn.RNN(input_size = letters_embedding_size, hidden_size = hidden_size,\n",
        "                         num_layers=num_layers, batch_first = True)\n",
        "    self.last_linear = nn.Linear(hidden_size,num_letters)\n",
        "\n",
        "  def forward(self, X):\n",
        "    N = X.shape[0]\n",
        "    L = X.shape[1]\n",
        "    embedded_letters = self.letters_embedder(X)\n",
        "    # Get hidden states for all letters in the sequence\n",
        "    hidden_states,_ = self.rnn(embedded_letters)\n",
        "    # In case of multiple input sequneces flat (N,L,hidden_size) to (N*L,hidden_size) for linear layer\n",
        "    hidden_states_concat = hidden_states.reshape(-1,self.hidden_size)\n",
        "    # Get letters probability using the hidden states for each position in the sequence\n",
        "    letters_loggits = self.last_linear(hidden_states_concat)\n",
        "    # Use soft-max over logits and reshape to format (N,L,num_letteres)\n",
        "    letters_probs = self.softmax(letters_loggits).reshape(N,L,self.num_letters)\n",
        "    return letters_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tx7WiFHim4yA"
      },
      "outputs": [],
      "source": [
        "def train_test(model, num_epochs, loss_fn, optimizer,\n",
        "               train_encrypted_loader, train_decrypted, test_encrypted, test_decrypted):\n",
        "\n",
        "    model = model.to(device)\n",
        "    # train_encrypted_loader = train_encrypted_loader.data.to(device)\n",
        "    train_decrypted = train_decrypted.to(device)\n",
        "    test_encrypted = test_encrypted.to(device)\n",
        "    test_decrypted = test_decrypted.to(device)\n",
        "\n",
        "    loss_hist = []\n",
        "    acc_hist = []\n",
        "    test_loss_hist = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # TRAINING AND BACK-PROPAGATION\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        letters_probs = model(next(iter(train_encrypted_loader)))\n",
        "        loss = loss_fn(letters_probs.log().permute(0,2,1), # rearrange as to (N_sequences, N_letters, N_lenght_sequences)\n",
        "                      train_decrypted)\n",
        "        loss.backward() # Backpropagate\n",
        "        optimizer.step() # Update weights\n",
        "        loss_hist.append(loss.item())\n",
        "\n",
        "        # EVALUATION\n",
        "        model.eval()\n",
        "        letters_probs = model(test_encrypted)\n",
        "        test_loss = loss_fn(letters_probs.log().permute(0,2,1), # rearrange as to (N_sequences, N_letters, N_lenght_sequences)\n",
        "                            test_decrypted)\n",
        "        _,maxprob_letters_idx = letters_probs.max(dim=2) # get letter with maximum prob\n",
        "        accuracy = ((maxprob_letters_idx==test_decrypted)*1.0).mean() # compute accuracy\n",
        "        test_loss_hist.append(test_loss.item())\n",
        "        acc_hist.append(accuracy.item())\n",
        "\n",
        "        if(epoch%50==0):\n",
        "          print(f'Epoch {epoch} \\t Train Loss {round(loss.item(),3)} \\t Test Loss {round(test_loss.item(),3)} \\t Test Acc. (%)  {round(accuracy.item()*100,1)}')\n",
        "    print(f'Final Epoch \\t Train Loss {round(loss.item(),3)} \\t Test Loss {round(test_loss.item(),3)} \\t Test Acc. (%)  {round(accuracy.item()*100,1)}')\n",
        "    return model,loss_hist, test_loss_hist, acc_hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yKu8yceVm4yA"
      },
      "outputs": [],
      "source": [
        "train_encrypted = torch.concat([train_sample[0].unsqueeze(0) for train_sample in train],dim=0)\n",
        "train_decrypted = torch.concat([train_sample[1].unsqueeze(0) for train_sample in train],dim=0)\n",
        "test_encrypted = torch.concat([test_sample[0].unsqueeze(0) for test_sample in test],dim=0)\n",
        "test_decrypted = torch.concat([test_sample[1].unsqueeze(0) for test_sample in test],dim=0)\n",
        "\n",
        "train_encrypted_dataset = CorruptedDataset(train_encrypted)\n",
        "train_encrypted_loader = DataLoader(train_encrypted_dataset, batch_size=len(train_encrypted_dataset), shuffle=False)\n",
        "\n",
        "decrypter_network = DecrypterNetwork(num_layers=2,\n",
        "                                    num_letters=len(corr_vocab),\n",
        "                                    hidden_size=16,\n",
        "                                    use_lstm=True)\n",
        "\n",
        "num_epochs=600\n",
        "CE_loss = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(decrypter_network.parameters(), lr=1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "16yHPKFUm4yA",
        "outputId": "f98ea2da-3510-4aca-b522-32e55bae66f3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-78762d645f2f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m decrypter_network, loss_hist, test_loss_hist, acc_hist = train_test(decrypter_network,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                  \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                  \u001b[0mCE_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                  \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                  train_encrypted_loader, train_decrypted, test_encrypted, test_decrypted)\n",
            "\u001b[0;32m<ipython-input-17-f170b695d5d7>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(model, num_epochs, loss_fn, optimizer, train_encrypted_loader, train_decrypted, test_encrypted, test_decrypted)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mletters_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_encrypted_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         loss = loss_fn(letters_probs.log().permute(0,2,1), # rearrange as to (N_sequences, N_letters, N_lenght_sequences)\n\u001b[1;32m     20\u001b[0m                       train_decrypted)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-0d91eecf58b6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0membedded_letters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mletters_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Get hidden states for all letters in the sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_letters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2235\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ],
      "source": [
        "decrypter_network, loss_hist, test_loss_hist, acc_hist = train_test(decrypter_network,\n",
        "                                                 num_epochs,\n",
        "                                                 CE_loss,\n",
        "                                                 optimizer,\n",
        "                                                 train_encrypted_loader, train_decrypted, test_encrypted, test_decrypted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBtHb4M9m4yA"
      },
      "outputs": [],
      "source": [
        "plt.plot(loss_hist, '-.r', linewidth=1.0, label='train_loss')\n",
        "plt.plot(test_loss_hist,'-b', linewidth=1.0, label='test_loss')\n",
        "plt.xlabel('train step', fontsize=14)\n",
        "plt.ylabel('loss', fontsize=14)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(acc_hist, linewidth=3.0, label='test_acc')\n",
        "plt.xlabel('train step', fontsize=14)\n",
        "plt.ylabel('accuracy(%)', fontsize=14)\n",
        "plt.ylim([0, 1])\n",
        "plt.xlim([0, num_epochs])\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "decrypter_network = decrypter_network.to(device)\n",
        "for idx_sample in range(0,10):\n",
        "  # Inference over single training sequence\n",
        "  letters_probs = decrypter_network(test[idx_sample][0].unsqueeze(0))\n",
        "  # get index of letter with max probability\n",
        "  _,maxprob_letters_idx = letters_probs.max(dim=2)\n",
        "  print('--------------------------------------')\n",
        "  print(f'Original Message encrypted: {int_to_vocabulary(test[idx_sample][0],corr_vocab)}')\n",
        "  print(f'Message decrypted: {int_to_vocabulary(test[idx_sample][1],vocabulary)}')\n",
        "  print(f'Prediction Message decrypted: {int_to_vocabulary(maxprob_letters_idx[0],corr_vocab)}')\n",
        "  acc = (1.0*(maxprob_letters_idx[0]==test[idx_sample][1])).mean().item()\n",
        "  print(f'Prediction Message Accuracy : {round(acc,2)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ECWZ8nBfnmn7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}