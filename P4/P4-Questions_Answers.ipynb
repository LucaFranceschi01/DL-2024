{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Practice 4"]},{"cell_type":"markdown","metadata":{},"source":["Student 1: Alejandro González Álvarez\n","\n","NIA 1: 252658\n","\n","Student 2: Luca Franceschi\n","\n","NIA 2: 253885\n","\n","Student 3: Júlia Othats-Dalès\n","\n","NIA 3: 254435"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torchinfo\n","import torchvision\n","import torchsummary\n","import numpy as np\n","from PIL import Image\n","import torch.nn as nn\n","import scipy.io as sio\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","metadata":{},"source":["# Google Drive (or not)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Comment if not in Google Colab\n","# !pip install torchinfo\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# data_path = '/content/drive/My Drive/DeepLearning_2024/P4/Data/'\n","# results_path = '/content/drive/My Drive/DeepLearning_2024/P4/Results/'\n","\n","# Comment if in Google Colab\n","data_path = 'Data/'\n","results_path = 'Results/'"]},{"cell_type":"markdown","metadata":{},"source":["# GPU Acceleration (or not)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Print if gpu acceleration is enabled\n","device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")"]},{"cell_type":"markdown","metadata":{"id":"IvcOz1eTrxRx"},"source":["# **Deep Generative Models: Variational Autoencoders and Generative Adversarial Networks**"]},{"cell_type":"markdown","metadata":{"id":"EvWs2XIYNfhg"},"source":["# **CK Dataset**\n","In the following exercices, you will work with images extracted from the CK dataset: http://www.jeffcohn.net/wp-content/uploads/2020/02/Cohn-Kanade_Database.pdf.pdf\n","\n","It contains gray-scale images of human faces.\n","\n","The dataset is provided in the folder Data/faces/ in .mat format.\n","In the following we provide a Dataset class in pytorch to load images from this database."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":290},"executionInfo":{"elapsed":43049,"status":"ok","timestamp":1653800688560,"user":{"displayName":"Adria Ruiz","userId":"10075760785236424538"},"user_tz":-120},"id":"5kE5D0hh1Ndz","outputId":"9483add6-4ad6-45c9-f5df-a2326394b6d9"},"outputs":[],"source":["# Create a Custom Dataset for CK database  \n","# All the data will be loaded from the provided file in Data/mnist.t\n","# Making native class loader\n","class FacesDB(torch.utils.data.Dataset):\n","    # Initialization method for the dataset\n","    def __init__(self,dataDir = data_path+'/faces/face_ims_64x64.mat', transform = None):\n","        mat_loaded = sio.loadmat(dataDir)\n","        self.data = mat_loaded['X']\n","        self.transform = transform\n","\n","    # What to do to load a single item in the dataset ( read image and label)\n","    def __getitem__(self, index):\n","        data = self.data[:,:,0,index]\n","        data = Image.fromarray(data,mode='L')\n","        # Apply a trasnformaiton to the image if it is indicated in the initalizer\n","        if self.transform is not None :\n","            data = self.transform(data)\n","\n","        # return the image and the label\n","        return data\n","\n","    # Return the number of images\n","    def __len__(self):\n","        return self.data.shape[3]\n","\n","tr = transforms.Compose([\n","        transforms.ToTensor(),\n","        ])\n","faces_db = FacesDB(data_path + '/faces/face_ims_64x64.mat', tr)\n","train_loader = torch.utils.data.DataLoader(dataset=faces_db,\n","                                           batch_size=256,\n","                                           shuffle=True)\n","\n","# Mini-batch images\n","images = next(iter(train_loader))\n","print(images.shape)\n","image = images[0, :, :, :].repeat(3, 1, 1)\n","plt.imshow(image.permute(1, 2, 0).squeeze().numpy())\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"CVA6m-IgNace"},"source":["# Ex. 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1653800688561,"user":{"displayName":"Adria Ruiz","userId":"10075760785236424538"},"user_tz":-120},"id":"y1yTECVjDVmf","outputId":"5285d823-5808-45c8-bbd9-c18510b02767"},"outputs":[],"source":["'''\n","1. Following the example of the MNIST, train a VAE with the images we have provided for the CK dataset.\n","2. For every two epochs during training:\n","  2.1. Visualize a set of reconstructed images and compute the reconstruction error over the whole dataset\n","  2.2. Generate and show a set of images from random noise z.\n","  2.3. Visualize a set of generated images by interpolating over the latent space z.\n","  2.4 Discuss the different visualizations by analysing their relation with the evolution of the reconstruction loss and the KL regularization term.\n","'''"]},{"cell_type":"markdown","metadata":{"id":"TPhaB5uN5nub"},"source":["## Sol. 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convolution + BatchNormnalization + ReLU block for the encoder\n","class ConvBNReLU(nn.Module):\n","  def __init__(self, in_channels, out_channels, pooling=False):\n","    super(ConvBNReLU, self).__init__()\n","    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding = 1)\n","    self.bn = nn.BatchNorm2d(out_channels)\n","    self.relu = nn.ReLU(inplace=True)\n","\n","    self.pool = None\n","    if(pooling):\n","      self.pool = nn.AvgPool2d(2, 2)\n","\n","  def forward(self,x):\n","    if(self.pool):\n","      out = self.pool(x)\n","    else:\n","      out = x\n","    out = self.relu(self.bn(self.conv(out)))\n","    return out\n","\n","#  BatchNormalization + ReLU block + Convolution for the decoder\n","class BNReLUConv(nn.Module):\n","  def __init__(self, in_channels, out_channels, pooling=False):\n","    super(BNReLUConv, self).__init__()\n","    self.bn = nn.BatchNorm2d(in_channels)\n","    self.relu = nn.ReLU(inplace=True)\n","    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding = 1)\n","\n","    self.pool = None\n","    if(pooling):\n","      self.pool = nn.UpsamplingNearest2d(scale_factor=2)\n","\n","  def forward(self,x):\n","    out = self.relu(self.bn(x))\n","    if(self.pool):\n","      out = self.pool(out)\n","    out = self.conv(out)\n","    return out\n","\n","# Encoder definition with 3 COnv-BN-ReLU blocks and fully-connected layer\n","class Encoder(nn.Module):\n","  def __init__(self, out_features, base_channels=16):\n","    super(Encoder, self).__init__()\n","    self.layer1 = ConvBNReLU(1, base_channels, pooling=False)\n","    self.layer2 = ConvBNReLU(base_channels, base_channels*2, pooling=True)\n","    self.layer3 = ConvBNReLU(base_channels*2, base_channels*4, pooling=True)\n","    self.fc = nn.Linear(16*16*base_channels*4, out_features)\n","\n","  def forward(self,x):\n","    out = self.layer1(x)\n","    out = self.layer2(out)\n","    out = self.layer3(out)\n","    return self.fc(out.view(x.shape[0], -1))\n","\n","# Decoder definition with a fully-connected layer and 3 BN-ReLU-COnv blocks and\n","class Decoder(nn.Module):\n","  def __init__(self, out_features, base_channels=16):\n","    super(Decoder, self).__init__()\n","    self.base_channels = base_channels\n","    self.fc = nn.Linear(out_features, 16*16*base_channels*4)\n","    self.layer3 = BNReLUConv(base_channels*4, base_channels*2, pooling=True)\n","    self.layer2 = BNReLUConv(base_channels*2, base_channels, pooling=True)\n","    self.layer1 = BNReLUConv(base_channels, 1, pooling=False)\n","\n","  def forward(self,x):\n","    out = self.fc(x)\n","    out = out.view(x.shape[0], self.base_channels*4, 16, 16)\n","    out = self.layer3(out)\n","    out = self.layer2(out)\n","    out = self.layer1(out)\n","    return torch.sigmoid(out)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class VAE(nn.Module):\n","  def __init__(self, out_features=32, base_channels=16):\n","    super(VAE, self).__init__()\n","    # Initialize the encoder and decoder using a dimensionality out_features for the vector z\n","    self.out_features = out_features\n","    self.encoder = Encoder(out_features*2, base_channels)\n","    self.decoder = Decoder(out_features, base_channels)\n","\n","  # function to obtain the mu and sigma of z for a samples x\n","  def encode(self,x):\n","    aux = self.encoder(x)\n","    # get z mean\n","    z_mean = aux[:, 0:self.out_features]\n","    # get z variance\n","    z_log_var = aux[:, self.out_features::]\n","    return z_mean, z_log_var\n","\n","  # function to generate a random sample z given mu and sigma\n","  def sample_z(self, z_mean, z_log_var):\n","    z_std = z_log_var.mul(0.5).exp()\n","    samples_unit_normal = torch.randn_like(z_mean)\n","    samples_z = samples_unit_normal*z_std + z_mean\n","    return samples_z\n","\n","  # (1) encode a sample\n","  # (2) obtain a random vector z from mu and sigma\n","  # (3) Reconstruct the image using the decoder\n","  def forward(self,x):\n","    z_mean, z_log_var = self.encode(x)\n","    samples_z = self.sample_z(z_mean, z_log_var)\n","    x_rec = self.decoder(samples_z)\n","    return x_rec, z_mean, z_log_var"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Kullback-Leibler regularization computation\n","def kl_divergence(z_mean,z_log_var):\n","  kl_loss = 0.5 * torch.sum((torch.exp(z_log_var) + z_mean**2 - 1.0 - z_log_var), axis=1)\n","  return kl_loss.mean()\n","\n","# Train function\n","def train_VAE(vae,  train_loader, optimizer, kl_weight=0.001, num_epochs=10, model_name='vae_mnist.ckpt', device='cpu'):\n","    vae.to(device)\n","    vae.train() # Set the model in train mode\n","    total_step = len(train_loader)\n","    losses_list = []\n","    criterion = nn.MSELoss() # Use mean-squared error to compare the original and reconstructe images\n","\n","    # Iterate over epochs\n","    for epoch in range(num_epochs):\n","        # Iterate the dataset\n","        rec_loss_avg = 0\n","        kl_loss_avg = 0\n","        nBatches = 0\n","        for i, images in enumerate(train_loader):\n","            # Get batch of samples and labels\n","            images = images.to(device)\n","\n","            # Forward pass (get encoder variables and reconstructed images)\n","            x_rec, z_mean, z_log_var = vae(images)\n","\n","            reconstruction_loss = criterion(x_rec, images) # Reconstruction loss (x,x_rec)\n","            kl_loss = kl_divergence(z_mean, z_log_var) # Compute KL divergecnes KL( N(mu_x,sigma_x) || N(0,I))\n","\n","            # Backward and optimize reconstruction loss and kl regularization\n","            optimizer.zero_grad()\n","            loss = reconstruction_loss + kl_loss*kl_weight # we use a weight to balance the importance of the KL loss\n","            loss.backward()\n","            optimizer.step()\n","\n","            rec_loss_avg += reconstruction_loss.cpu().item()\n","            kl_loss_avg += kl_loss.cpu().item()\n","\n","            nBatches+=1\n","            if (i+1) % 100 == 0:\n","                print ('Epoch [{}/{}], Step [{}/{}], Rec. Loss: {:.4f}, KL Loss: {:.4f}'\n","                       .format(epoch+1, num_epochs, i+1, total_step, rec_loss_avg / nBatches, kl_loss_avg / nBatches))\n","        print ('Epoch [{}/{}], Step [{}/{}], Rec. Loss: {:.4f}, KL Loss: {:.4f}'\n","                       .format(epoch+1, num_epochs, i+1, total_step, rec_loss_avg / nBatches, kl_loss_avg / nBatches))\n","        losses_list.append(rec_loss_avg / nBatches)\n","        # save trained model\n","        torch.save(vae.state_dict(), results_path+ '/' + model_name)\n","\n","    return losses_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Training a VAE on CK: z has 64 dimensions\n","# We use Adam optimizer which is tipically used in VAEs and GANs\n","\n","vae = VAE(out_features=64)\n","kl_weight = 0.1\n","\n","#Initialize optimizer\n","learning_rate = 0.001\n","optimizer = torch.optim.Adam(vae.parameters(), lr = learning_rate, weight_decay=1e-5)\n","\n","loss_list = train_VAE(vae, train_loader, optimizer, kl_weight=kl_weight,\n","                      num_epochs=20, model_name='vae_ck.ckpt', device=device)"]},{"cell_type":"markdown","metadata":{"id":"FhQbpBkQ5ux0"},"source":["# Ex. 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1653800688561,"user":{"displayName":"Adria Ruiz","userId":"10075760785236424538"},"user_tz":-120},"id":"J5zT1eRf5ux4","outputId":"9236d987-b00b-45e1-9669-07756d7a9ea5"},"outputs":[],"source":["'''\n","1. Following the example of the MNIST , train a GAN with the images we have provided for the CK dataset.\n","2. For every two epochs during training:\n","  2.1. Generate and show a set of images from random noise z.\n","  2.2. Visualize a set of generated images by interpolating over the latent space z.\n","  2.3 Discuss the different visualizations by analysing their relation between their quality and the evolution of the discriminator and generator losses.\n","Compare the results with the ones obtained with VAEs\n","'''"]},{"cell_type":"markdown","metadata":{"id":"vUrqAof5JRjH"},"source":["## Sol. 2"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Discriminator similar to VAE encoder\n","class Discriminator(nn.Module):\n","  def __init__(self, base_channels=16):\n","    super(Discriminator, self).__init__()\n","    # last fully connected layer acts as a a binary classifier\n","    self.classifier = Encoder(1,base_channels)\n","\n","  # Forward pass obtaining the discriminator probability\n","  def forward(self,x):\n","    out = self.classifier(x)\n","    # use sigmoid to get the real/fake image probability\n","    return torch.sigmoid(out)\n","\n","# Generator is defined as VAE decoder\n","class Generator(nn.Module):\n","  def __init__(self,in_features,base_channels=16):\n","    super(Generator, self).__init__()\n","    self.base_channels = base_channels\n","    self.in_features = in_features\n","    self.decoder = Decoder(in_features,base_channels)\n","\n","  # Generate an image from vector z\n","  def forward(self,z):\n","    return torch.sigmoid(self.decoder(z))\n","\n","  # Sample a set of images from random vectors z\n","  def sample(self,n_samples=256,device='cpu'):\n","    samples_unit_normal = torch.randn((n_samples,self.in_features)).to(device)\n","    return self.decoder(samples_unit_normal)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# GAN Train function. We have a generator and discriminator models and their respective optimizers.\n","def train_GAN(gen, disc,  train_loader, optimizer_gen, optimizer_disc,\n","              num_epochs=10, model_name='gan_ck.ckpt', device='cpu'):\n","    gen = gen.to(device)\n","    gen.train() # Set the generator in train mode\n","    disc = disc.to(device)\n","    disc.train() # Set the discriminator in train mode\n","\n","    total_step = len(train_loader)\n","    losses_list = []\n","\n","    # Iterate over epochs\n","    for epoch in range(num_epochs):\n","        # Iterate the dataset\n","        disc_loss_avg = 0\n","        gen_loss_avg = 0\n","        nBatches = 0\n","        update_generator = True\n","\n","        for i, real_images in enumerate(train_loader):\n","            # Get batch of samples and labels\n","            real_images = real_images.to(device)\n","            n_images = real_images.shape[0]\n","\n","            # Forward pass\n","            # Generate random images with the generator\n","            fake_images = gen.sample(n_images,device=device)\n","\n","            # Use the discriminator to obtain the probabilties for real and generate imee\n","            prob_real = disc(real_images)\n","            prob_fake = disc(fake_images)\n","\n","            # Generator loss\n","            gen_loss = -torch.log(prob_fake).mean()\n","            # Discriminator loss\n","            disc_loss = -0.5*(torch.log(prob_real) + torch.log(1-prob_fake)).mean()\n","\n","\n","            # We are going to update the discriminator and generator parameters alternatively at each iteration\n","            if(update_generator):\n","              # Optimize generator\n","              # Backward and optimize\n","              optimizer_gen.zero_grad()\n","              gen_loss.backward() # Necessary to not erase intermediate variables needed for computing disc_loss gradient\n","              optimizer_gen.step()\n","              update_generator = False\n","            else:\n","              # Optimize discriminator\n","              # Backward and optimize\n","              optimizer_disc.zero_grad()\n","              disc_loss.backward()\n","              optimizer_disc.step()\n","              update_generator = True\n","\n","\n","            disc_loss_avg += disc_loss.cpu().item()\n","            gen_loss_avg += gen_loss.cpu().item()\n","\n","            nBatches+=1\n","            if (i+1) % 200 == 0:\n","                print ('Epoch [{}/{}], Step [{}/{}], Gen. Loss: {:.4f}, Disc Loss: {:.4f}'\n","                       .format(epoch+1, num_epochs, i+1, total_step, gen_loss_avg / nBatches, disc_loss_avg / nBatches))\n","        print ('Epoch [{}/{}], Step [{}/{}], Gen. Loss: {:.4f}, Disc Loss: {:.4f}'\n","                       .format(epoch+1, num_epochs, i+1, total_step, gen_loss_avg / nBatches, disc_loss_avg / nBatches))\n","        # Save model\n","        losses_list.append(disc_loss_avg / nBatches)\n","        torch.save(gen.state_dict(), results_path+ '/' + model_name)\n","\n","    return losses_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define Generator and Discriminator networks\n","gan_gen = Generator(64)\n","gan_disc = Discriminator()\n","\n","#Initialize independent optimizer for both networks\n","learning_rate = .0005\n","optimizer_gen = torch.optim.Adam(gan_gen.parameters(), lr = learning_rate, weight_decay=1e-5)\n","optimizer_disc = torch.optim.Adam(gan_disc.parameters(), lr = learning_rate, weight_decay=1e-5)\n","\n","# Train the GAN\n","loss_list = train_GAN(gan_gen,gan_disc, train_loader, optimizer_gen, optimizer_disc,\n","                      num_epochs=20, model_name='gan_ck.ckpt', device=device)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
